{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on backward variational ICA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Uncomment and run the following cell if you're using Collab***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf *\n",
    "# !git clone https://github.com/mchagneux/backward_ica.git\n",
    "# !mv backward_ica/* ./\n",
    "# !rm -rf backward_ica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from src.elbo import linear_gaussian_elbo\n",
    "from src.hmm import LinearGaussianHMM\n",
    "from src import kalman\n",
    "from jax.random import PRNGKey\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import optax\n",
    "from jax import random\n",
    "from src.misc import *\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "# jax.config.update(\"jax_debug_nans\", True)\n",
    "key = PRNGKey(0)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook is comprised of a series of experiments that attempt to recover expectations $\\mathbb{E}[h(z_{1:t})|x_{1:t}]$ via variational approximations, when the process $(z_t, x_t)_{t \\ge 1}$ is an HMM. The main metric $\\ell$ all along is the MSE against the true states when $h$ is a plain sum, ie\n",
    "\n",
    "$$\\ell = \\left(\\sum_{t=1}^T z_t^* - \\sum_{t=1}^T \\mathbb{E}_{q_T(z_t)}[z_t] \\right)^2$$\n",
    "\n",
    "where $q_T(z_t) = q(z_t|x_{1:T})$ is the marginal smoothing distribution at $t$.\n",
    "\n",
    "In all the following, we assume that the variational smoothing distribution factorizes as $q_\\phi(z_{1:t}|x_{1:t}) = q_\\phi(z_t|x_{1:t}) \\prod_{s=1}^{t-1} q_\\phi(z_s|z_{s+1},x_{1:s})$. We always assume that $$q_\\phi(z_t|x_{1:t}) \\sim \\mathcal{N}(\\mu_{1:t}, \\Sigma_{1:t})$$ and \n",
    "\n",
    "$$q_\\phi(z_s|z_{s+1},x_{1:s}) \\sim \\mathcal{N}(\\overleftarrow{\\mu}_{1:t}(z_{s+1}), \\overleftarrow{\\Sigma}_{1:t})$$\n",
    "\n",
    "In the following, we make several assumptions on both $p_\\theta$ and $q_\\phi$.\n",
    "\n",
    "\n",
    "In this case, not only should the expectations be correctly recovered, but parameters in $\\phi$ and $\\theta$ should be identifiable. We also know that in this case the best estimate of $z_{1:t}^*$ for any sequence is obtained via the Kalman smoothing recursions applied with parameters $\\theta$ on the observations $x_{1:t}$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Gaussian HMM \n",
    "\n",
    "First we assume that observation sequences $x_{1:T}$ arise from $p_\\theta(z_{1:t},x_{1:t})$ defined as\n",
    "$$z_t = A_\\theta z_{t-1} + a_\\theta + \\eta_\\theta$$ \n",
    "$$x_t = B_\\theta z_t + b_\\theta + \\epsilon_\\theta$$\n",
    "\n",
    "where $\\eta_\\theta \\sim \\mathcal{N}(0,Q_\\theta)$ and $\\epsilon_\\theta \\sim \\mathcal{N}(0,R_\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. a. Approximated by a linear Gaussian HMM\n",
    "\n",
    "We start by recovering $p_\\theta$ when $q_\\phi$ is in the family of the true p. We do this by prescribing the p for $q_\\phi$ in forward time with a similar HMM structure as $p_\\theta$ (but random initial parameters), and in this case the parameters of the filtering backward distributions exist via Kalman recursions and closed-form definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking that $\\mathcal{L}(\\theta, \\theta) = \\log p_\\theta$ \n",
    "*Remark: here $\\log p$ is computed with Kalman*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of simulated observations: 480\n",
      "Difference mean evidence Kalman and mean ELBO when q=p: 1.4210854715202004e-14\n"
     ]
    }
   ],
   "source": [
    "state_dim, obs_dim = 2, 2 \n",
    "num_sequences = 30\n",
    "length = 16\n",
    "print('Total amount of simulated observations:', num_sequences * length)\n",
    "key, *subkeys = random.split(key,3)\n",
    "\n",
    "p_raw = LinearGaussianHMM.get_random_model(key=subkeys[0], state_dim=state_dim, obs_dim=obs_dim)\n",
    "\n",
    "p = actual_model_from_raw_parameters(p_raw)\n",
    "\n",
    "linear_gaussian_sampler = jax.vmap(LinearGaussianHMM.sample_joint_sequence, in_axes=(0, None, None))\n",
    "key, *subkeys = random.split(key, num_sequences+1)\n",
    "state_sequences, obs_sequences = linear_gaussian_sampler(jnp.array(subkeys), p, length)\n",
    "\n",
    "\n",
    "filter_obs_sequences = jax.vmap(kalman.filter, in_axes=(0, None))\n",
    "elbo_sequences = jax.vmap(linear_gaussian_elbo, in_axes=(None, None, 0))\n",
    "\n",
    "average_evidence_across_sequences = jnp.mean(filter_obs_sequences(obs_sequences, p)[-1])\n",
    "average_elbo_across_sequences_with_true_model = jnp.mean(elbo_sequences(p_raw, p_raw, obs_sequences))\n",
    "print('Difference mean evidence Kalman and mean ELBO when q=p:', jnp.abs(average_evidence_across_sequences-average_elbo_across_sequences_with_true_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing $\\phi$ when $\\theta$ is fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different mean evidence and mean ELBO when q=q0: 81626.75174598196\n"
     ]
    }
   ],
   "source": [
    "def step(p_raw, q_raw, opt_state, batch):\n",
    "    loss_value, grads = jax.value_and_grad(linear_gaussian_elbo, argnums=1)(p_raw, q_raw, batch)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, q_raw)\n",
    "    q_raw = optax.apply_updates(q_raw, updates)\n",
    "    return p_raw, q_raw, opt_state, -loss_value\n",
    "step = jax.jit(step)\n",
    "q_raw = LinearGaussianHMM.get_random_model(key=subkeys[1], state_dim=state_dim, obs_dim=obs_dim)\n",
    "average_elbo_across_sequences_with_init_q = jnp.mean(elbo_sequences(p_raw, q_raw, obs_sequences))\n",
    "print('Different mean evidence and mean ELBO when q=q0:', jnp.abs(average_evidence_across_sequences-average_elbo_across_sequences_with_init_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = optax.adam(learning_rate=-1e-2)\n",
    "\n",
    "def fit(p_raw, q_raw, optimizer: optax.GradientTransformation) -> optax.Params:\n",
    "    opt_state = optimizer.init(q_raw)\n",
    "\n",
    "    eps = jnp.inf\n",
    "    old_mean_epoch_elbo = -average_elbo_across_sequences_with_init_q\n",
    "    epoch_nb = 0\n",
    "    mean_elbos = [old_mean_epoch_elbo - average_evidence_across_sequences]\n",
    "    while eps > 1e-2:\n",
    "        epoch_elbo = 0.0\n",
    "        for batch in obs_sequences: \n",
    "            p_raw, q_raw, opt_state, elbo_value = step(p_raw, q_raw, opt_state, batch)\n",
    "            epoch_elbo += elbo_value\n",
    "        mean_epoch_elbo = epoch_elbo/len(obs_sequences)\n",
    "        eps = jnp.abs(mean_epoch_elbo - old_mean_epoch_elbo)\n",
    "        epoch_nb+=1\n",
    "        mean_elbos.append(mean_epoch_elbo - average_evidence_across_sequences)\n",
    "        old_mean_epoch_elbo = mean_epoch_elbo\n",
    "    return q_raw, mean_elbos\n",
    "\n",
    "\n",
    "fitted_q_raw, mean_elbos = fit(p_raw, q_raw, optimizer)\n",
    "\n",
    "plt.plot(mean_elbos)\n",
    "plt.xlabel('Epoch nb'), \n",
    "plt.ylabel('Mean of $\\mathcal{L}(\\\\theta,\\phi) - log p_{\\\\theta}$')\n",
    "fitted_q = actual_model_from_raw_parameters(fitted_q_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing expectations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(E_q(h(z)), z_true): [0.02397306 0.04839656]\n",
      "MSE(E_p(h(z)), z_true): [0.02379176 0.04110415]\n"
     ]
    }
   ],
   "source": [
    "def squared_error_expectation_against_true_states(states, observations, approximate_linear_gaussian_model, additive_functional):\n",
    "    smoothed_states, _ = kalman.smooth(observations, approximate_linear_gaussian_model)\n",
    "    return jnp.sqrt((additive_functional(smoothed_states) - additive_functional(states)) ** 2)\n",
    "\n",
    "additive_functional = partial(jnp.sum, axis=0)\n",
    "mse_in_expectations = jax.vmap(squared_error_expectation_against_true_states, in_axes=(0,0, None, None))\n",
    "print('MSE(E_q(h(z)), z_true):', jnp.mean(mse_in_expectations(state_sequences, obs_sequences, fitted_q, additive_functional), axis=0))\n",
    "print('MSE(E_p(h(z)), z_true):', jnp.mean(mse_in_expectations(state_sequences, obs_sequences, p, additive_functional), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing values of phi and theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi: Model(prior=Prior(mean=DeviceArray([0.11017476, 0.3605916 ], dtype=float64), cov=DeviceArray([[6.17799658e-05, 0.00000000e+00],\n",
      "             [0.00000000e+00, 1.10925771e-04]], dtype=float64)), transition=Transition(weight=DeviceArray([[0.08922846, 0.        ],\n",
      "             [0.        , 0.62011269]], dtype=float64), bias=DeviceArray([0.26371705, 0.87742689], dtype=float64), cov=DeviceArray([[6.69855390e-05, 0.00000000e+00],\n",
      "             [0.00000000e+00, 8.21407316e-05]], dtype=float64)), emission=Observation(weight=DeviceArray([[0.26268696, 0.        ],\n",
      "             [0.        , 0.4076881 ]], dtype=float64), bias=DeviceArray([0.61678799, 1.02496611], dtype=float64), cov=DeviceArray([[3.17292721e-05, 0.00000000e+00],\n",
      "             [0.00000000e+00, 1.07355797e-04]], dtype=float64)))\n",
      "theta: Model(prior=Prior(mean=DeviceArray([0.02758312, 0.00267917], dtype=float64), cov=DeviceArray([[0.0001, 0.    ],\n",
      "             [0.    , 0.0001]], dtype=float64)), transition=Transition(weight=DeviceArray([[0.13738688, 0.        ],\n",
      "             [0.        , 0.69740022]], dtype=float64), bias=DeviceArray([0.25169768, 0.69862585], dtype=float64), cov=DeviceArray([[0.0001, 0.    ],\n",
      "             [0.    , 0.0001]], dtype=float64)), emission=Observation(weight=DeviceArray([[0.85648701, 0.        ],\n",
      "             [0.        , 0.61750934]], dtype=float64), bias=DeviceArray([0.44666786, 0.54389377], dtype=float64), cov=DeviceArray([[0.0001, 0.    ],\n",
      "             [0.    , 0.0001]], dtype=float64)))\n"
     ]
    }
   ],
   "source": [
    "print('phi:', fitted_q)\n",
    "print('theta:',p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. b. Using a neural network to compute the backward parameters instead of Kalman recursions\n",
    "We make the same assumptions on $p_\\theta$ but now we attempt to recover the backward parameters via neural network.\n",
    "\n",
    "*TODO*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A nonlinear emission p\n",
    "\n",
    "We now assume that $p_\\theta$ has a nonlinear emission distribution, ie. $x_t  = f_\\theta(z_t) + \\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. a. Approximated by a linear Gaussian p.\n",
    "We keep a linear gaussian distribution for $q_\\phi$, but we add a mapping to compute the expectation of the emission term from $p_\\theta$. We need to approximate the following quantity:\n",
    "\n",
    "$$\\mathbb{E}_{q(z_t|z_{t+1}, x_{1:t})}\\left[(x_t - f_\\theta(z_t))^T R^{{\\theta}^{-1}}(x_t - f_\\theta(z_t))\\right]$$\n",
    "\n",
    "And similarly for the last expectation under the filtering distribution: \n",
    "\n",
    "$$\\mathbb{E}_{q(z_T|x_{1:T})}\\left[(x_T - f_\\theta(z_T))^T R^{{\\theta}^{-1}}(x_T - f_\\theta(z_T))\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. a. i. A sampling-free approach. \n",
    "\n",
    "\n",
    "If we know the expectation $\\mu$ and variance $\\Sigma$ of a random variable $v$ (which need not be Gaussian):\n",
    "\n",
    "$$\\mathbb{E}_{v}\\left[(x - v)^T \\Omega (x - v)\\right] = tr(\\Sigma \\Omega) + (\\mu - x)^T \\Omega (\\mu - x)$$\n",
    "\n",
    "Suppose we a have neural network which approximates the mean and variance of $v \\sim f_\\theta(z)$ when $z \\sim p_z$, given parameters of $p_z$. Denote $\\tilde{\\mu}$ and $\\tilde{\\Sigma}$ these means and variances estimated by this network. For the filtering case, we feed the network with filtering mean and covariance at $T$ to obtain an estimate of $\\tilde{\\mu}$ and $\\tilde{\\Sigma}$, then:\n",
    "\n",
    "$$\\mathbb{E}_{q(z_T|x_{1:T})}\\left[(x_T - f_\\theta(z_T))^T R^{{\\theta}^{-1}}(x_T - f_\\theta(z_T))\\right] = tr(\\tilde{\\Sigma} \\Omega) + (\\tilde{\\mu} - x)^T R^{{\\theta}^{-1}} (\\tilde{\\mu} - x)$$\n",
    "\n",
    "For the backwards case this is not as simple, because: $\\overleftarrow{\\mu}_{1:t}$ is a function of $z_{t+1}$, therefore $\\mathbb{E}_{q(z_t|z_{t+1}, x_{1:t})}[f_\\theta(z_t)]$ and $\\mathbb{V}_{q(z_t|z_{t+1}, x_{1:t})}[f_\\theta(z_t)]$ are also functions of $z_{t+1}$. \n",
    "\n",
    "We still attempt to use one network for both the fitlering and the backwards via the following scheme: \n",
    "\n",
    "- Build a neural network $g_\\alpha(A, a, \\Sigma)$ which outputs $\\tilde{A}, \\tilde{a}$ and $\\tilde{\\Sigma}$\n",
    "- For the backwards case, use $A = \\overleftarrow{A}_{1:t}, a = \\overleftarrow{a}_{1:t}$ and $\\Sigma = \\overleftarrow{\\Sigma}_{1:t}$, and consider that $\\tilde{\\mu} = \\tilde{A}z_{t+1} + \\tilde{a}$, while $\\tilde{\\Sigma}$ does not depend on $z_{t+1}$ (which is knowingly false). In this case, the quadratic form build for $\\tilde{A}$ and $\\tilde{a}$ is a quadratic form in $z_{t+1}$ as wanted.\n",
    "- For the backwards case, use $A = 0, a = a_{1:t}$ and $\\Sigma = \\Sigma_{1:t}$, and consider that $\\tilde{\\mu} = \\tilde{a}$ (without using the output $\\tilde{A}$).\n",
    "\n",
    "*This method, which is tried below: fails to learn anything as of now.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### not reimplemented in JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. a. i. The Johnson trick\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c528143767b35424e5fa616681845f3b9656c31f35cafe040129ce40f24d14f5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('backward_ica')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
