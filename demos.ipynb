{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on backward variational ICA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Uncomment and run the following cell if you're using Collab***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf *\n",
    "# !git clone https://github.com/mchagneux/backward_ica.git\n",
    "# !mv backward_ica/* ./\n",
    "# !rm -rf backward_ica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(-2.8422e-14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/chagneux/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/container.py:597: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from src.eval import mse_expectation_against_true_states\n",
    "from src.kalman import Kalman, NumpyKalman\n",
    "from src.hmm import AdditiveGaussianHMM, LinearGaussianHMM\n",
    "from src.elbo import get_appropriate_elbo\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "torch.set_default_dtype(torch.float64) \n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "# torch.set_printoptions(precision=10)\n",
    "\n",
    "## sanity checks\n",
    "hmm = LinearGaussianHMM(state_dim=2, obs_dim=2)\n",
    "states, observations = hmm.sample_joint_sequence(10)\n",
    "\n",
    "for param in hmm.model.parameters():param.requires_grad = False\n",
    "likelihood_torch = Kalman(hmm.model).filter(observations)[4] #kalman with torch operators \n",
    "likelihood_numpy = NumpyKalman(hmm.model).filter(observations.numpy())[2] #kalman with numpy operators \n",
    "fully_linear_gaussian_elbo = get_appropriate_elbo('linear_gaussian','linear_emission')\n",
    "likelihood_via_elbo = fully_linear_gaussian_elbo(hmm.model, hmm.model)(observations) #elbo\n",
    "\n",
    "# both should be close to 0\n",
    "print(likelihood_numpy - likelihood_torch)\n",
    "print(likelihood_numpy - likelihood_via_elbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook is comprised of a series of experiments that attempt to recover expectations $\\mathbb{E}[h(z_{1:t})|x_{1:t}]$ via variational approximations, when the process $(z_t, x_t)_{t \\ge 1}$ is an HMM. The main metric $\\ell$ all along is the MSE against the true states when $h$ is a plain sum, ie\n",
    "\n",
    "$$\\ell = \\left(\\sum_{t=1}^T z_t^* - \\sum_{t=1}^T \\mathbb{E}_{q_T(z_t)}[z_t] \\right)^2$$\n",
    "\n",
    "where $q_T(z_t) = q(z_t|x_{1:T})$ is the marginal smoothing distribution at $t$.\n",
    "\n",
    "In all the following, we assume that the variational smoothing distribution factorizes as $q_\\phi(z_{1:t}|x_{1:t}) = q_\\phi(z_t|x_{1:t}) \\prod_{s=1}^{t-1} q_\\phi(z_s|z_{s+1},x_{1:s})$. We always assume that $$q_\\phi(z_t|x_{1:t}) \\sim \\mathcal{N}(\\mu_{1:t}, \\Sigma_{1:t})$$ and \n",
    "\n",
    "$$q_\\phi(z_s|z_{s+1},x_{1:s}) \\sim \\mathcal{N}(\\overleftarrow{\\mu}_{1:t}(z_{s+1}), \\overleftarrow{\\Sigma}_{1:t})$$\n",
    "\n",
    "In the following, we make several assumptions on both $p_\\theta$ and $q_\\phi$.\n",
    "\n",
    "\n",
    "In this case, not only should the expectations be correctly recovered, but parameters in $\\phi$ and $\\theta$ should be identifiable. We also know that in this case the best estimate of $z_{1:t}^*$ for any sequence is obtained via the Kalman smoothing recursions applied with parameters $\\theta$ on the observations $x_{1:t}$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Gaussian HMM \n",
    "\n",
    "First we assume that observation sequences $x_{1:T}$ arise from $p_\\theta(z_{1:t},x_{1:t})$ defined as\n",
    "$$z_t = A_\\theta z_{t-1} + a_\\theta + \\eta_\\theta$$ \n",
    "$$x_t = B_\\theta z_t + b_\\theta + \\epsilon_\\theta$$\n",
    "\n",
    "where $\\eta_\\theta \\sim \\mathcal{N}(0,Q_\\theta)$ and $\\epsilon_\\theta \\sim \\mathcal{N}(0,R_\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. a. Approximated by a linear Gaussian HMM\n",
    "\n",
    "We start by recovering $p_\\theta$ when $q_\\phi$ is in the family of the true p. We do this by prescribing the p for $q_\\phi$ in forward time with a similar HMM structure as $p_\\theta$ (but random initial parameters), and in this case the parameters of the filtering backward distributions exist via Kalman recursions and closed-form definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True evidence accross all sequences: tensor(297.0628)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(8504.1103)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2597.4656)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1320.4481)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(581.7610)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(291.8398)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(130.9565)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(68.4381)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(41.3779)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(32.5424)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(28.5845)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(26.7188)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(24.8722)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(23.5791)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(22.4512)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(21.3992)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(20.5358)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(19.6738)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(18.8974)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(18.1550)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(17.4584)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(16.8007)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(16.1814)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(15.5972)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(15.0471)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(14.5289)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(14.0407)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(13.5807)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(13.1471)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(12.7382)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(12.3525)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(11.9884)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(11.6446)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(11.3198)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(11.0127)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(10.7224)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(10.4476)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(10.1876)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(9.9414)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(9.7081)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(9.4871)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(9.2776)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(9.0789)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(8.8904)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(8.7114)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(8.5415)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(8.3802)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(8.2268)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(8.0810)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(7.9422)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(7.8102)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(7.6844)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(7.5646)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(7.4504)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(7.3414)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(7.2373)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(7.1379)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(7.0428)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.9519)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.8648)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.7813)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.7013)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.6245)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.5507)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.4798)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.4116)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.3459)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.2825)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.2215)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.1625)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.1055)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.0505)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.9972)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.9456)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.8955)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.8470)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.7999)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.7542)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.7097)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.6665)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.6244)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.5835)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.5436)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.5047)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.4668)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.4297)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.3936)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.3583)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.3239)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.2902)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.2573)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.2251)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.1936)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.1628)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.1326)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.1031)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.0742)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.0459)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.0182)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.9910)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.9644)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.9384)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.9128)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.8878)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.8633)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.8393)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.8158)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.7927)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.7701)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.7479)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.7262)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.7050)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.6841)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.6637)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.6437)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.6241)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.6049)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.5861)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.5677)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.5496)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.5320)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.5147)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.4977)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.4811)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.4648)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.4489)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.4333)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.4180)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.4030)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.3884)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.3739)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.3598)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.3459)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.3323)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.3189)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.3058)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.2928)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.2800)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.2674)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.2549)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.2426)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.2304)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.2183)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.2062)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.1942)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.1822)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.1701)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.1581)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.1460)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.1338)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.1215)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.1091)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.0965)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.0838)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.0708)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.0576)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.0442)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.0305)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.0165)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.0022)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.9876)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.9726)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.9574)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.9418)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.9259)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.9096)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.8930)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.8760)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.8587)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.8411)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.8232)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.8050)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.7866)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.7678)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.7489)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.7297)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.7104)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.6908)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.6711)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.6514)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.6315)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.6115)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.5915)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.5715)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.5515)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.5315)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.5115)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.4916)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.4718)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.4521)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.4325)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.4130)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.3937)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.3745)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.3555)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.3366)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.3179)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.2994)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.2810)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.2628)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.2448)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.2270)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.2094)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.1919)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.1746)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.1575)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.1406)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.1238)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.1072)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.0907)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.0744)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.0583)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.0423)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.0264)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.0107)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.9952)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.9797)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.9644)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.9492)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.9341)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.9192)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.9043)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.8896)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.8750)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.8604)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.8460)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.8316)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.8174)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.8032)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.7891)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.7751)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.7612)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.7473)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.7336)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.7198)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.7062)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.6926)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.6791)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.6656)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.6522)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.6389)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.6256)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.6124)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.5992)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.5860)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.5729)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.5599)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.5468)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.5339)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.5209)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.5080)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.4952)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.4823)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.4696)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.4568)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.4441)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.4313)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.4187)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.4060)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.3934)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.3808)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.3682)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.3556)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.3431)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.3306)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.3181)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.3056)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.2931)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.2806)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.2682)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.2558)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.2433)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.2309)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.2185)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.2061)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.1937)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.1813)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.1689)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.1565)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.1441)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.1317)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.1193)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.1069)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.0945)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.0821)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.0697)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.0573)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.0448)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.0324)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.0199)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.0074)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.9949)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.9824)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.9699)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.9573)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.9447)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.9321)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.9194)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.9068)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.8940)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.8813)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.8685)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.8557)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.8428)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.8299)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.8170)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.8040)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.7909)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.7778)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.7647)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.7515)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.7382)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.7249)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.7115)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.6980)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.6845)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.6709)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.6572)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.6434)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.6296)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.6157)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.6017)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5876)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5734)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5592)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5448)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5304)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5158)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5012)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.4865)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.4716)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.4567)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.4417)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.4266)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.4113)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.3960)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.3806)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.3651)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.3495)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.3337)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.3180)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.3021)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.2861)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.2701)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.2539)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.2377)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.2215)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.2051)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.1887)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.1723)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.1558)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.1393)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.1228)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.1062)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.0896)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.0730)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.0565)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.0399)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.0234)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.0068)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.9904)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.9740)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.9576)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.9413)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.9252)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.9091)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8931)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8772)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8614)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8458)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8303)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8150)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7998)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7848)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7700)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7554)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7410)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7268)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7128)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6990)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6854)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6721)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6589)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6461)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6334)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6210)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6088)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5969)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5852)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5738)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5626)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5517)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5409)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5304)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5202)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5102)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5004)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4908)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4815)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4724)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4635)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4548)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4463)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4380)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4299)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4220)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4143)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4068)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3995)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3924)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3854)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3787)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3721)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3656)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3593)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3532)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3472)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3414)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3358)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3302)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3248)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3196)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3144)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3094)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3045)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2998)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2951)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2905)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2860)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2816)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2773)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2731)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2689)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2647)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2606)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2566)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2525)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2485)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2445)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2404)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2364)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2323)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2282)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2241)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2199)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2157)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2115)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2073)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2030)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1988)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1945)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1903)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1861)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1820)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1780)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1741)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1702)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1665)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1629)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1595)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1561)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1529)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1498)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1467)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1438)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1410)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1383)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1357)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1332)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1307)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1283)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1260)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1237)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1215)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1193)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1173)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1152)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1132)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1113)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1094)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1075)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1057)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1039)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1022)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1005)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.0988)\n"
     ]
    }
   ],
   "source": [
    "hmm = LinearGaussianHMM(state_dim=2, obs_dim=2) # pick some true p p \n",
    "for param in hmm.model.parameters(): param.requires_grad = False # not learning the parameters of the true p for now \n",
    "\n",
    "\n",
    "\n",
    "# sampling 10 sequences from the hmm \n",
    "samples = [hmm.sample_joint_sequence(8) for _ in range(10)] \n",
    "state_sequences = [sample[0] for sample in samples]\n",
    "observation_sequences = [sample[1] for sample in samples] \n",
    "\n",
    "\n",
    "# the variational p is a random LGMM with same dimensions, and we will not learn the covariances for now\n",
    "q = LinearGaussianHMM.get_random_model(2,2)\n",
    "q.prior.parametrizations.cov.original.requires_grad = False\n",
    "q.transition.parametrizations.cov.original.requires_grad = False \n",
    "q.emission.parametrizations.cov.original.requires_grad = False \n",
    "\n",
    "# the elbo object with p and q as arguments\n",
    "elbo = fully_linear_gaussian_elbo(hmm.model, q)\n",
    "\n",
    "# optimize the parameters of the ELBO (but theta deactivated above)\n",
    "optimizer = torch.optim.Adam(params=elbo.parameters(), lr=1e-2)\n",
    "true_evidence_all_sequences = sum(Kalman(hmm.model).filter(observations)[-1] for observations in observation_sequences)\n",
    "\n",
    "print('True evidence accross all sequences:', true_evidence_all_sequences)\n",
    "\n",
    "eps = torch.inf\n",
    "# optimizing p \n",
    "while eps > 0.1:\n",
    "    epoch_loss = 0.0\n",
    "    for observations in observation_sequences: \n",
    "        optimizer.zero_grad()\n",
    "        loss = -elbo(observations)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += -loss\n",
    "    with torch.no_grad():\n",
    "        eps = torch.abs(true_evidence_all_sequences - epoch_loss)\n",
    "        print('Average of \"L(theta, phi) - log(p_theta(x))\":', eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE when smoothed with p: tensor(0.0082)\n",
      "MSE when smoothed with q: tensor(0.0079)\n"
     ]
    }
   ],
   "source": [
    "# checking expectations under approximate p when the additive functional is just the sum \n",
    "with torch.no_grad():\n",
    "    additive_functional = partial(torch.sum, dim=0)\n",
    "    smoothed_with_true_model = mse_expectation_against_true_states(state_sequences, observation_sequences, hmm.model, additive_functional)\n",
    "    smoothed_with_approximate_model = mse_expectation_against_true_states(state_sequences, observation_sequences, q, additive_functional)\n",
    "\n",
    "    print('MSE when smoothed with p:',smoothed_with_true_model)\n",
    "    print('MSE when smoothed with q:',smoothed_with_approximate_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. b. Using a neural network to compute the backward parameters instead of Kalman recursions\n",
    "We make the same assumptions on $p_\\theta$ but now we attempt to recover the backward parameters via neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A nonlinear emission p\n",
    "\n",
    "We now assume that $p_\\theta$ has a nonlinear emission distribution, ie. $x_t  = f_\\theta(z_t) + \\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. a. Approximated by a linear Gaussian p.\n",
    "We keep a linear gaussian distribution for $q_\\phi$, but we add a mapping to compute the expectation of the emission term from $p_\\theta$. We need to approximate the following quantity:\n",
    "\n",
    "$$\\mathbb{E}_{q(z_t|z_{t+1}, x_{1:t})}\\left[(x_t - f_\\theta(z_t))^T R^{{\\theta}^{-1}}(x_t - f_\\theta(z_t))\\right]$$\n",
    "\n",
    "And similarly for the last expectation under the filtering distribution: \n",
    "\n",
    "$$\\mathbb{E}_{q(z_T|x_{1:T})}\\left[(x_T - f_\\theta(z_T))^T R^{{\\theta}^{-1}}(x_T - f_\\theta(z_T))\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. a. i. A sampling-free approach. \n",
    "\n",
    "\n",
    "If we know the expectation $\\mu$ and variance $\\Sigma$ of a random variable $v$ (which need not be Gaussian):\n",
    "\n",
    "$$\\mathbb{E}_{v}\\left[(x - v)^T \\Omega (x - v)\\right] = tr(\\Sigma \\Omega) + (\\mu - x)^T \\Omega (\\mu - x)$$\n",
    "\n",
    "Suppose we a have neural network which approximates the mean and variance of $v \\sim f_\\theta(z)$ when $z \\sim p_z$, given parameters of $p_z$. Denote $\\tilde{\\mu}$ and $\\tilde{\\Sigma}$ these means and variances estimated by this network. For the filtering case, we feed the network with filtering mean and covariance at $T$ to obtain an estimate of $\\tilde{\\mu}$ and $\\tilde{\\Sigma}$, then:\n",
    "\n",
    "$$\\mathbb{E}_{q(z_T|x_{1:T})}\\left[(x_T - f_\\theta(z_T))^T R^{{\\theta}^{-1}}(x_T - f_\\theta(z_T))\\right] = tr(\\tilde{\\Sigma} \\Omega) + (\\tilde{\\mu} - x)^T R^{{\\theta}^{-1}} (\\tilde{\\mu} - x)$$\n",
    "\n",
    "For the backwards case this is not as simple, because: $\\overleftarrow{\\mu}_{1:t}$ is a function of $z_{t+1}$, therefore $\\mathbb{E}_{q(z_t|z_{t+1}, x_{1:t})}[f_\\theta(z_t)]$ and $\\mathbb{V}_{q(z_t|z_{t+1}, x_{1:t})}[f_\\theta(z_t)]$ are also functions of $z_{t+1}$. \n",
    "\n",
    "We still attempt to use one network for both the fitlering and the backwards via the following scheme: \n",
    "\n",
    "- Build a neural network $g_\\alpha(A, a, \\Sigma)$ which outputs $\\tilde{A}, \\tilde{a}$ and $\\tilde{\\Sigma}$\n",
    "- For the backwards case, use $A = \\overleftarrow{A}_{1:t}, a = \\overleftarrow{a}_{1:t}$ and $\\Sigma = \\overleftarrow{\\Sigma}_{1:t}$, and consider that $\\tilde{\\mu} = \\tilde{A}z_{t+1} + \\tilde{a}$, while $\\tilde{\\Sigma}$ does not depend on $z_{t+1}$ (which is knowingly false). In this case, the quadratic form build for $\\tilde{A}$ and $\\tilde{a}$ is a quadratic form in $z_{t+1}$ as wanted.\n",
    "- For the backwards case, use $A = 0, a = a_{1:t}$ and $\\Sigma = \\Sigma_{1:t}$, and consider that $\\tilde{\\mu} = \\tilde{a}$ (without using the output $\\tilde{A}$).\n",
    "\n",
    "*This method, which is tried below: fails to learn anything as of now.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_quad_form_in_emission_term() missing 1 required positional argument: 'z'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/infres/chagneux/repos/backward_ica/demos.ipynb Cell 15'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/home/infres/chagneux/repos/backward_ica/demos.ipynb#ch0000014vscode-remote?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m observations \u001b[39min\u001b[39;00m observation_sequences: \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/home/infres/chagneux/repos/backward_ica/demos.ipynb#ch0000014vscode-remote?line=32'>33</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/home/infres/chagneux/repos/backward_ica/demos.ipynb#ch0000014vscode-remote?line=33'>34</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39melbo(observations)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/home/infres/chagneux/repos/backward_ica/demos.ipynb#ch0000014vscode-remote?line=34'>35</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/home/infres/chagneux/repos/backward_ica/demos.ipynb#ch0000014vscode-remote?line=35'>36</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/repos/backward_ica/src/elbo.py:137\u001b[0m, in \u001b[0;36mBackwardELBO.forward\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=133'>134</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit(observations[\u001b[39m0\u001b[39m])\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=135'>136</a>\u001b[0m \u001b[39mfor\u001b[39;00m observation \u001b[39min\u001b[39;00m observations[\u001b[39m1\u001b[39m:]:\n\u001b[0;32m--> <a href='file:///~/repos/backward_ica/src/elbo.py?line=136'>137</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update(observation)\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=137'>138</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstants_V \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39m_constant_terms_from_log_gaussian(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_z, torch\u001b[39m.\u001b[39mdet(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiltering_params\u001b[39m.\u001b[39mcov))\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=139'>140</a>\u001b[0m result \u001b[39m=\u001b[39m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expect_V_under_filtering()\n",
      "File \u001b[0;32m~/repos/backward_ica/src/elbo.py:114\u001b[0m, in \u001b[0;36mBackwardELBO._update\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=111'>112</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_backward()\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=112'>113</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_filtering(observation)\n\u001b[0;32m--> <a href='file:///~/repos/backward_ica/src/elbo.py?line=113'>114</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_V(observation)\n",
      "File \u001b[0;32m~/repos/backward_ica/src/elbo.py:186\u001b[0m, in \u001b[0;36mLinearGaussianQ._update_V\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=182'>183</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_V\u001b[39m(\u001b[39mself\u001b[39m, observation):\n\u001b[0;32m--> <a href='file:///~/repos/backward_ica/src/elbo.py?line=185'>186</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_integrate_previous_terms()\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=187'>188</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstants_V \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m _constant_terms_from_log_gaussian(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp_emission_det_cov) \\\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=188'>189</a>\u001b[0m                     \u001b[39m+\u001b[39m  _constant_terms_from_log_gaussian(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_z, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp_transition_det_cov) \\\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=189'>190</a>\u001b[0m                     \u001b[39m+\u001b[39m \u001b[39m-\u001b[39m_constant_terms_from_log_gaussian(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_z, torch\u001b[39m.\u001b[39mdet(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward_params\u001b[39m.\u001b[39mcov)) \\\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=190'>191</a>\u001b[0m                     \u001b[39m+\u001b[39m  \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_z, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat64) \\\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=191'>192</a>\u001b[0m                     \u001b[39m+\u001b[39m \u001b[39m-\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mtrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp_transition_prec \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp\u001b[39m.\u001b[39mtransition\u001b[39m.\u001b[39mmap\u001b[39m.\u001b[39mweight \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward_params\u001b[39m.\u001b[39mcov \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp\u001b[39m.\u001b[39mtransition\u001b[39m.\u001b[39mmap\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mT)\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=193'>194</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransition_terms\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expect_transition_quad_form_under_backward())\n",
      "File \u001b[0;32m~/repos/backward_ica/src/elbo.py:180\u001b[0m, in \u001b[0;36mLinearGaussianQ._integrate_previous_terms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=177'>178</a>\u001b[0m \u001b[39mfor\u001b[39;00m term_nb, (transition_term, obs_term) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransition_terms, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_terms)):\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=178'>179</a>\u001b[0m     constants_0, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransition_terms[term_nb] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expect_quad_form_under_backward(transition_term)\n\u001b[0;32m--> <a href='file:///~/repos/backward_ica/src/elbo.py?line=179'>180</a>\u001b[0m     constants_1, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_terms[term_nb] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_expect_obs_term_under_backward(obs_term)\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=180'>181</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstants_V \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m constants_0 \u001b[39m+\u001b[39m constants_1\n",
      "File \u001b[0;32m~/repos/backward_ica/src/elbo.py:274\u001b[0m, in \u001b[0;36mNonLinearEmission._expect_obs_term_under_backward\u001b[0;34m(self, obs_term)\u001b[0m\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=271'>272</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_expect_obs_term_under_backward\u001b[39m(\u001b[39mself\u001b[39m, obs_term):\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=272'>273</a>\u001b[0m     observation \u001b[39m=\u001b[39m obs_term\n\u001b[0;32m--> <a href='file:///~/repos/backward_ica/src/elbo.py?line=273'>274</a>\u001b[0m     nonlinear_map \u001b[39m=\u001b[39m partial(_quad_form_in_emission_term(observation\u001b[39m=\u001b[39;49mobservation, \n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=274'>275</a>\u001b[0m                                                         emission_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp\u001b[39m.\u001b[39;49memission\u001b[39m.\u001b[39;49mmap, \n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=275'>276</a>\u001b[0m                                                         emission_prec\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp_emission_prec))\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=277'>278</a>\u001b[0m     v, W \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapproximator(filtering_params\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiltering_params, \n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=278'>279</a>\u001b[0m                             backward_params\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward_params, \n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=279'>280</a>\u001b[0m                             nonlinear_map\u001b[39m=\u001b[39mnonlinear_map)\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=281'>282</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m QuadForm(Omega\u001b[39m=\u001b[39mW, \n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=282'>283</a>\u001b[0m                     A\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39meye(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_x),\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=283'>284</a>\u001b[0m                     b\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mv)\n",
      "\u001b[0;31mTypeError\u001b[0m: _quad_form_in_emission_term() missing 1 required positional argument: 'z'"
     ]
    }
   ],
   "source": [
    "hmm = AdditiveGaussianHMM(state_dim=2, obs_dim=2) # we now take an hmm wih \n",
    "\n",
    "# sampling 10 sequences from the hmm \n",
    "samples = [hmm.sample_joint_sequence(8) for _ in range(10)] \n",
    "state_sequences = [sample[0] for sample in samples]\n",
    "observation_sequences = [sample[1] for sample in samples] \n",
    "\n",
    "\n",
    "# the variational p is a random LGMM with same dimensions, and we will not learn the covariances for now\n",
    "q = LinearGaussianHMM.get_random_model(2,2)\n",
    "q.prior.parametrizations.cov.original.requires_grad = False\n",
    "q.transition.parametrizations.cov.original.requires_grad = False \n",
    "q.emission.parametrizations.cov.original.requires_grad = False \n",
    "\n",
    "\n",
    "elbo_nonlinear_emission = get_appropriate_elbo(q_description='linear_gaussian', \n",
    "                                            p_description='nonlinear_emission')\n",
    "\n",
    "elbo = elbo_nonlinear_emission(hmm.model, q)\n",
    "\n",
    "# print(elbo_nonlinear_emission(observation_sequences[0]))\n",
    "\n",
    "\n",
    "\n",
    "# optimize the parameters of the ELBO (but theta deactivated above)\n",
    "optimizer = torch.optim.Adam(params=elbo.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "eps = torch.inf\n",
    "# optimizing p \n",
    "while True:\n",
    "    epoch_loss = 0.0\n",
    "    for observations in observation_sequences: \n",
    "        optimizer.zero_grad()\n",
    "        loss = -elbo(observations)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += -loss\n",
    "    with torch.no_grad():\n",
    "        print(\"Loss:\", epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. a. i. Sampling and the Johnson trick.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c528143767b35424e5fa616681845f3b9656c31f35cafe040129ce40f24d14f5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('backward_ica')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
