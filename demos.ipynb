{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on backward variational ICA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Uncomment and run the following cell if you're using Collab***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf *\n",
    "# !git clone https://github.com/mchagneux/backward_ica.git\n",
    "# !mv backward_ica/* ./\n",
    "# !rm -rf backward_ica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.1054e-15)\n",
      "tensor(-2.8422e-14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathis/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/container.py:597: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "torch.set_default_dtype(torch.float64) \n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "from functools import partial\n",
    "\n",
    "from src.eval import mse_expectation_against_true_states\n",
    "from src.kalman import Kalman, NumpyKalman\n",
    "from src.hmm import AdditiveGaussianHMM, LinearGaussianHMM\n",
    "from src.elbo import get_appropriate_elbo\n",
    "# torch.set_printoptions(precision=10)\n",
    "\n",
    "## sanity checks\n",
    "hmm = LinearGaussianHMM(state_dim=2, obs_dim=2)\n",
    "states, observations = hmm.sample_joint_sequence(10)\n",
    "\n",
    "for param in hmm.model.parameters():param.requires_grad = False\n",
    "likelihood_torch = Kalman(hmm.model).filter(observations)[4] #kalman with torch operators \n",
    "likelihood_numpy = NumpyKalman(hmm.model).filter(observations.numpy())[2] #kalman with numpy operators \n",
    "fully_linear_gaussian_elbo = get_appropriate_elbo('linear_gaussian','linear_emission')\n",
    "likelihood_via_elbo = fully_linear_gaussian_elbo(hmm.model, hmm.model)(observations) #elbo\n",
    "\n",
    "# both should be close to 0\n",
    "print(likelihood_numpy - likelihood_torch)\n",
    "print(likelihood_numpy - likelihood_via_elbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook is comprised of a series of experiments that attempt to recover expectations $\\mathbb{E}[h(z_{1:t})|x_{1:t}]$ via variational approximations, when the process $(z_t, x_t)_{t \\ge 1}$ is an HMM. The main metric $\\ell$ all along is the MSE against the true states when $h$ is a plain sum, ie\n",
    "\n",
    "$$\\ell = \\left(\\sum_{t=1}^T z_t^* - \\sum_{t=1}^T \\mathbb{E}_{q_T(z_t)}[z_t] \\right)^2$$\n",
    "\n",
    "where $q_T(z_t) = q(z_t|x_{1:T})$ is the marginal smoothing distribution at $t$.\n",
    "\n",
    "In all the following, we assume that the variational smoothing distribution factorizes as $q_\\phi(z_{1:t}|x_{1:t}) = q_\\phi(z_t|x_{1:t}) \\prod_{s=1}^{t-1} q_\\phi(z_s|z_{s+1},x_{1:s})$. We always assume that $$q_\\phi(z_t|x_{1:t}) \\sim \\mathcal{N}(\\mu_{1:t}, \\Sigma_{1:t})$$ and \n",
    "\n",
    "$$q_\\phi(z_s|z_{s+1},x_{1:s}) \\sim \\mathcal{N}(\\overleftarrow{\\mu}_{1:t}(z_{s+1}), \\overleftarrow{\\Sigma}_{1:t})$$\n",
    "\n",
    "In the following, we make several assumptions on both $p_\\theta$ and $q_\\phi$.\n",
    "\n",
    "\n",
    "In this case, not only should the expectations be correctly recovered, but parameters in $\\phi$ and $\\theta$ should be identifiable. We also know that in this case the best estimate of $z_{1:t}^*$ for any sequence is obtained via the Kalman smoothing recursions applied with parameters $\\theta$ on the observations $x_{1:t}$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Gaussian HMM \n",
    "\n",
    "First we assume that observation sequences $x_{1:T}$ arise from $p_\\theta(z_{1:t},x_{1:t})$ defined as\n",
    "$$z_t = A_\\theta z_{t-1} + a_\\theta + \\eta_\\theta$$ \n",
    "$$x_t = B_\\theta z_t + b_\\theta + \\epsilon_\\theta$$\n",
    "\n",
    "where $\\eta_\\theta \\sim \\mathcal{N}(0,Q_\\theta)$ and $\\epsilon_\\theta \\sim \\mathcal{N}(0,R_\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. a. Approximated by a linear Gaussian HMM\n",
    "\n",
    "We start by recovering $p_\\theta$ when $q_\\phi$ is in the family of the true p. We do this by prescribing the p for $q_\\phi$ in forward time with a similar HMM structure as $p_\\theta$ (but random initial parameters), and in this case the parameters of the filtering backward distributions exist via Kalman recursions and closed-form definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathis/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/container.py:597: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True evidence accross all sequences: tensor(298.9847)\n",
      "Epoch gain w.r.t to objective: tensor(inf)\n",
      "Epoch gain w.r.t to objective: tensor(52984.8457)\n",
      "Epoch gain w.r.t to objective: tensor(11180.8882)\n",
      "Epoch gain w.r.t to objective: tensor(2283.8153)\n",
      "Epoch gain w.r.t to objective: tensor(2449.6759)\n",
      "Epoch gain w.r.t to objective: tensor(1178.3995)\n",
      "Epoch gain w.r.t to objective: tensor(902.9804)\n",
      "Epoch gain w.r.t to objective: tensor(666.8344)\n",
      "Epoch gain w.r.t to objective: tensor(513.4298)\n",
      "Epoch gain w.r.t to objective: tensor(404.8531)\n",
      "Epoch gain w.r.t to objective: tensor(335.3184)\n",
      "Epoch gain w.r.t to objective: tensor(287.6167)\n",
      "Epoch gain w.r.t to objective: tensor(255.8584)\n",
      "Epoch gain w.r.t to objective: tensor(234.5712)\n",
      "Epoch gain w.r.t to objective: tensor(216.0975)\n",
      "Epoch gain w.r.t to objective: tensor(200.6539)\n",
      "Epoch gain w.r.t to objective: tensor(185.4191)\n",
      "Epoch gain w.r.t to objective: tensor(170.7478)\n",
      "Epoch gain w.r.t to objective: tensor(156.2305)\n",
      "Epoch gain w.r.t to objective: tensor(142.1538)\n",
      "Epoch gain w.r.t to objective: tensor(128.6088)\n",
      "Epoch gain w.r.t to objective: tensor(115.7460)\n",
      "Epoch gain w.r.t to objective: tensor(103.6682)\n",
      "Epoch gain w.r.t to objective: tensor(92.4346)\n",
      "Epoch gain w.r.t to objective: tensor(82.0876)\n",
      "Epoch gain w.r.t to objective: tensor(72.6305)\n",
      "Epoch gain w.r.t to objective: tensor(64.0547)\n",
      "Epoch gain w.r.t to objective: tensor(56.3306)\n",
      "Epoch gain w.r.t to objective: tensor(49.4198)\n",
      "Epoch gain w.r.t to objective: tensor(43.2745)\n",
      "Epoch gain w.r.t to objective: tensor(37.8421)\n",
      "Epoch gain w.r.t to objective: tensor(33.0670)\n",
      "Epoch gain w.r.t to objective: tensor(28.8925)\n",
      "Epoch gain w.r.t to objective: tensor(25.2624)\n",
      "Epoch gain w.r.t to objective: tensor(22.1221)\n",
      "Epoch gain w.r.t to objective: tensor(19.4195)\n",
      "Epoch gain w.r.t to objective: tensor(17.1055)\n",
      "Epoch gain w.r.t to objective: tensor(15.1345)\n",
      "Epoch gain w.r.t to objective: tensor(13.4645)\n",
      "Epoch gain w.r.t to objective: tensor(12.0570)\n",
      "Epoch gain w.r.t to objective: tensor(10.8774)\n",
      "Epoch gain w.r.t to objective: tensor(9.8946)\n",
      "Epoch gain w.r.t to objective: tensor(9.0807)\n",
      "Epoch gain w.r.t to objective: tensor(8.4113)\n",
      "Epoch gain w.r.t to objective: tensor(7.8646)\n",
      "Epoch gain w.r.t to objective: tensor(7.4217)\n",
      "Epoch gain w.r.t to objective: tensor(7.0661)\n",
      "Epoch gain w.r.t to objective: tensor(6.7836)\n",
      "Epoch gain w.r.t to objective: tensor(6.5620)\n",
      "Epoch gain w.r.t to objective: tensor(6.3907)\n",
      "Epoch gain w.r.t to objective: tensor(6.2607)\n",
      "Epoch gain w.r.t to objective: tensor(6.1645)\n",
      "Epoch gain w.r.t to objective: tensor(6.0958)\n",
      "Epoch gain w.r.t to objective: tensor(6.0491)\n",
      "Epoch gain w.r.t to objective: tensor(6.0198)\n",
      "Epoch gain w.r.t to objective: tensor(6.0044)\n",
      "Epoch gain w.r.t to objective: tensor(5.9997)\n",
      "Epoch gain w.r.t to objective: tensor(6.0031)\n",
      "Epoch gain w.r.t to objective: tensor(6.0125)\n",
      "Epoch gain w.r.t to objective: tensor(6.0263)\n",
      "Epoch gain w.r.t to objective: tensor(6.0428)\n",
      "Epoch gain w.r.t to objective: tensor(6.0611)\n",
      "Epoch gain w.r.t to objective: tensor(6.0801)\n",
      "Epoch gain w.r.t to objective: tensor(6.0991)\n",
      "Epoch gain w.r.t to objective: tensor(6.1174)\n",
      "Epoch gain w.r.t to objective: tensor(6.1345)\n",
      "Epoch gain w.r.t to objective: tensor(6.1500)\n",
      "Epoch gain w.r.t to objective: tensor(6.1635)\n",
      "Epoch gain w.r.t to objective: tensor(6.1747)\n",
      "Epoch gain w.r.t to objective: tensor(6.1834)\n",
      "Epoch gain w.r.t to objective: tensor(6.1892)\n",
      "Epoch gain w.r.t to objective: tensor(6.1922)\n",
      "Epoch gain w.r.t to objective: tensor(6.1919)\n",
      "Epoch gain w.r.t to objective: tensor(6.1885)\n",
      "Epoch gain w.r.t to objective: tensor(6.1816)\n",
      "Epoch gain w.r.t to objective: tensor(6.1712)\n",
      "Epoch gain w.r.t to objective: tensor(6.1573)\n",
      "Epoch gain w.r.t to objective: tensor(6.1396)\n",
      "Epoch gain w.r.t to objective: tensor(6.1182)\n",
      "Epoch gain w.r.t to objective: tensor(6.0930)\n",
      "Epoch gain w.r.t to objective: tensor(6.0640)\n",
      "Epoch gain w.r.t to objective: tensor(6.0310)\n",
      "Epoch gain w.r.t to objective: tensor(5.9941)\n",
      "Epoch gain w.r.t to objective: tensor(5.9533)\n",
      "Epoch gain w.r.t to objective: tensor(5.9085)\n",
      "Epoch gain w.r.t to objective: tensor(5.8598)\n",
      "Epoch gain w.r.t to objective: tensor(5.8072)\n",
      "Epoch gain w.r.t to objective: tensor(5.7507)\n",
      "Epoch gain w.r.t to objective: tensor(5.6903)\n",
      "Epoch gain w.r.t to objective: tensor(5.6263)\n",
      "Epoch gain w.r.t to objective: tensor(5.5585)\n",
      "Epoch gain w.r.t to objective: tensor(5.4871)\n",
      "Epoch gain w.r.t to objective: tensor(5.4122)\n",
      "Epoch gain w.r.t to objective: tensor(5.3339)\n",
      "Epoch gain w.r.t to objective: tensor(5.2523)\n",
      "Epoch gain w.r.t to objective: tensor(5.1677)\n",
      "Epoch gain w.r.t to objective: tensor(5.0800)\n",
      "Epoch gain w.r.t to objective: tensor(4.9895)\n",
      "Epoch gain w.r.t to objective: tensor(4.8963)\n",
      "Epoch gain w.r.t to objective: tensor(4.8007)\n",
      "Epoch gain w.r.t to objective: tensor(4.7028)\n",
      "Epoch gain w.r.t to objective: tensor(4.6027)\n",
      "Epoch gain w.r.t to objective: tensor(4.5008)\n",
      "Epoch gain w.r.t to objective: tensor(4.3972)\n",
      "Epoch gain w.r.t to objective: tensor(4.2920)\n",
      "Epoch gain w.r.t to objective: tensor(4.1856)\n",
      "Epoch gain w.r.t to objective: tensor(4.0782)\n",
      "Epoch gain w.r.t to objective: tensor(3.9699)\n",
      "Epoch gain w.r.t to objective: tensor(3.8609)\n",
      "Epoch gain w.r.t to objective: tensor(3.7516)\n",
      "Epoch gain w.r.t to objective: tensor(3.6420)\n",
      "Epoch gain w.r.t to objective: tensor(3.5325)\n",
      "Epoch gain w.r.t to objective: tensor(3.4231)\n",
      "Epoch gain w.r.t to objective: tensor(3.3142)\n",
      "Epoch gain w.r.t to objective: tensor(3.2059)\n",
      "Epoch gain w.r.t to objective: tensor(3.0984)\n",
      "Epoch gain w.r.t to objective: tensor(2.9919)\n",
      "Epoch gain w.r.t to objective: tensor(2.8865)\n",
      "Epoch gain w.r.t to objective: tensor(2.7824)\n",
      "Epoch gain w.r.t to objective: tensor(2.6798)\n",
      "Epoch gain w.r.t to objective: tensor(2.5789)\n",
      "Epoch gain w.r.t to objective: tensor(2.4796)\n",
      "Epoch gain w.r.t to objective: tensor(2.3823)\n",
      "Epoch gain w.r.t to objective: tensor(2.2870)\n",
      "Epoch gain w.r.t to objective: tensor(2.1938)\n",
      "Epoch gain w.r.t to objective: tensor(2.1027)\n",
      "Epoch gain w.r.t to objective: tensor(2.0140)\n",
      "Epoch gain w.r.t to objective: tensor(1.9276)\n",
      "Epoch gain w.r.t to objective: tensor(1.8436)\n",
      "Epoch gain w.r.t to objective: tensor(1.7621)\n",
      "Epoch gain w.r.t to objective: tensor(1.6831)\n",
      "Epoch gain w.r.t to objective: tensor(1.6067)\n",
      "Epoch gain w.r.t to objective: tensor(1.5329)\n",
      "Epoch gain w.r.t to objective: tensor(1.4616)\n",
      "Epoch gain w.r.t to objective: tensor(1.3929)\n",
      "Epoch gain w.r.t to objective: tensor(1.3268)\n",
      "Epoch gain w.r.t to objective: tensor(1.2633)\n",
      "Epoch gain w.r.t to objective: tensor(1.2024)\n",
      "Epoch gain w.r.t to objective: tensor(1.1440)\n",
      "Epoch gain w.r.t to objective: tensor(1.0881)\n",
      "Epoch gain w.r.t to objective: tensor(1.0346)\n",
      "Epoch gain w.r.t to objective: tensor(0.9836)\n",
      "Epoch gain w.r.t to objective: tensor(0.9350)\n",
      "Epoch gain w.r.t to objective: tensor(0.8887)\n",
      "Epoch gain w.r.t to objective: tensor(0.8447)\n",
      "Epoch gain w.r.t to objective: tensor(0.8029)\n",
      "Epoch gain w.r.t to objective: tensor(0.7632)\n",
      "Epoch gain w.r.t to objective: tensor(0.7257)\n",
      "Epoch gain w.r.t to objective: tensor(0.6901)\n",
      "Epoch gain w.r.t to objective: tensor(0.6565)\n",
      "Epoch gain w.r.t to objective: tensor(0.6248)\n",
      "Epoch gain w.r.t to objective: tensor(0.5949)\n",
      "Epoch gain w.r.t to objective: tensor(0.5668)\n",
      "Epoch gain w.r.t to objective: tensor(0.5403)\n",
      "Epoch gain w.r.t to objective: tensor(0.5155)\n",
      "Epoch gain w.r.t to objective: tensor(0.4922)\n",
      "Epoch gain w.r.t to objective: tensor(0.4703)\n",
      "Epoch gain w.r.t to objective: tensor(0.4499)\n",
      "Epoch gain w.r.t to objective: tensor(0.4308)\n",
      "Epoch gain w.r.t to objective: tensor(0.4129)\n",
      "Epoch gain w.r.t to objective: tensor(0.3963)\n",
      "Epoch gain w.r.t to objective: tensor(0.3809)\n",
      "Epoch gain w.r.t to objective: tensor(0.3665)\n",
      "Epoch gain w.r.t to objective: tensor(0.3532)\n",
      "Epoch gain w.r.t to objective: tensor(0.3409)\n",
      "Epoch gain w.r.t to objective: tensor(0.3295)\n",
      "Epoch gain w.r.t to objective: tensor(0.3189)\n",
      "Epoch gain w.r.t to objective: tensor(0.3093)\n",
      "Epoch gain w.r.t to objective: tensor(0.3004)\n",
      "Epoch gain w.r.t to objective: tensor(0.2922)\n",
      "Epoch gain w.r.t to objective: tensor(0.2848)\n",
      "Epoch gain w.r.t to objective: tensor(0.2780)\n",
      "Epoch gain w.r.t to objective: tensor(0.2719)\n",
      "Epoch gain w.r.t to objective: tensor(0.2663)\n",
      "Epoch gain w.r.t to objective: tensor(0.2613)\n",
      "Epoch gain w.r.t to objective: tensor(0.2568)\n",
      "Epoch gain w.r.t to objective: tensor(0.2529)\n",
      "Epoch gain w.r.t to objective: tensor(0.2493)\n",
      "Epoch gain w.r.t to objective: tensor(0.2463)\n",
      "Epoch gain w.r.t to objective: tensor(0.2436)\n",
      "Epoch gain w.r.t to objective: tensor(0.2414)\n",
      "Epoch gain w.r.t to objective: tensor(0.2395)\n",
      "Epoch gain w.r.t to objective: tensor(0.2380)\n",
      "Epoch gain w.r.t to objective: tensor(0.2368)\n",
      "Epoch gain w.r.t to objective: tensor(0.2359)\n",
      "Epoch gain w.r.t to objective: tensor(0.2353)\n",
      "Epoch gain w.r.t to objective: tensor(0.2351)\n",
      "Epoch gain w.r.t to objective: tensor(0.2350)\n",
      "Epoch gain w.r.t to objective: tensor(0.2353)\n",
      "Epoch gain w.r.t to objective: tensor(0.2357)\n",
      "Epoch gain w.r.t to objective: tensor(0.2364)\n",
      "Epoch gain w.r.t to objective: tensor(0.2373)\n",
      "Epoch gain w.r.t to objective: tensor(0.2385)\n",
      "Epoch gain w.r.t to objective: tensor(0.2398)\n",
      "Epoch gain w.r.t to objective: tensor(0.2413)\n",
      "Epoch gain w.r.t to objective: tensor(0.2430)\n",
      "Epoch gain w.r.t to objective: tensor(0.2449)\n",
      "Epoch gain w.r.t to objective: tensor(0.2469)\n",
      "Epoch gain w.r.t to objective: tensor(0.2491)\n",
      "Epoch gain w.r.t to objective: tensor(0.2515)\n",
      "Epoch gain w.r.t to objective: tensor(0.2540)\n",
      "Epoch gain w.r.t to objective: tensor(0.2566)\n",
      "Epoch gain w.r.t to objective: tensor(0.2593)\n",
      "Epoch gain w.r.t to objective: tensor(0.2622)\n",
      "Epoch gain w.r.t to objective: tensor(0.2652)\n",
      "Epoch gain w.r.t to objective: tensor(0.2683)\n",
      "Epoch gain w.r.t to objective: tensor(0.2715)\n",
      "Epoch gain w.r.t to objective: tensor(0.2748)\n",
      "Epoch gain w.r.t to objective: tensor(0.2782)\n",
      "Epoch gain w.r.t to objective: tensor(0.2817)\n",
      "Epoch gain w.r.t to objective: tensor(0.2852)\n",
      "Epoch gain w.r.t to objective: tensor(0.2888)\n",
      "Epoch gain w.r.t to objective: tensor(0.2925)\n",
      "Epoch gain w.r.t to objective: tensor(0.2962)\n",
      "Epoch gain w.r.t to objective: tensor(0.2999)\n",
      "Epoch gain w.r.t to objective: tensor(0.3037)\n",
      "Epoch gain w.r.t to objective: tensor(0.3074)\n",
      "Epoch gain w.r.t to objective: tensor(0.3112)\n",
      "Epoch gain w.r.t to objective: tensor(0.3150)\n",
      "Epoch gain w.r.t to objective: tensor(0.3187)\n",
      "Epoch gain w.r.t to objective: tensor(0.3225)\n",
      "Epoch gain w.r.t to objective: tensor(0.3261)\n",
      "Epoch gain w.r.t to objective: tensor(0.3298)\n",
      "Epoch gain w.r.t to objective: tensor(0.3333)\n",
      "Epoch gain w.r.t to objective: tensor(0.3368)\n",
      "Epoch gain w.r.t to objective: tensor(0.3401)\n",
      "Epoch gain w.r.t to objective: tensor(0.3434)\n",
      "Epoch gain w.r.t to objective: tensor(0.3465)\n",
      "Epoch gain w.r.t to objective: tensor(0.3495)\n",
      "Epoch gain w.r.t to objective: tensor(0.3523)\n",
      "Epoch gain w.r.t to objective: tensor(0.3549)\n",
      "Epoch gain w.r.t to objective: tensor(0.3573)\n",
      "Epoch gain w.r.t to objective: tensor(0.3595)\n",
      "Epoch gain w.r.t to objective: tensor(0.3616)\n",
      "Epoch gain w.r.t to objective: tensor(0.3633)\n",
      "Epoch gain w.r.t to objective: tensor(0.3649)\n",
      "Epoch gain w.r.t to objective: tensor(0.3662)\n",
      "Epoch gain w.r.t to objective: tensor(0.3672)\n",
      "Epoch gain w.r.t to objective: tensor(0.3679)\n",
      "Epoch gain w.r.t to objective: tensor(0.3683)\n",
      "Epoch gain w.r.t to objective: tensor(0.3685)\n",
      "Epoch gain w.r.t to objective: tensor(0.3683)\n",
      "Epoch gain w.r.t to objective: tensor(0.3679)\n",
      "Epoch gain w.r.t to objective: tensor(0.3671)\n",
      "Epoch gain w.r.t to objective: tensor(0.3661)\n",
      "Epoch gain w.r.t to objective: tensor(0.3647)\n",
      "Epoch gain w.r.t to objective: tensor(0.3630)\n",
      "Epoch gain w.r.t to objective: tensor(0.3610)\n",
      "Epoch gain w.r.t to objective: tensor(0.3587)\n",
      "Epoch gain w.r.t to objective: tensor(0.3561)\n",
      "Epoch gain w.r.t to objective: tensor(0.3533)\n",
      "Epoch gain w.r.t to objective: tensor(0.3501)\n",
      "Epoch gain w.r.t to objective: tensor(0.3467)\n",
      "Epoch gain w.r.t to objective: tensor(0.3431)\n",
      "Epoch gain w.r.t to objective: tensor(0.3392)\n",
      "Epoch gain w.r.t to objective: tensor(0.3350)\n",
      "Epoch gain w.r.t to objective: tensor(0.3307)\n",
      "Epoch gain w.r.t to objective: tensor(0.3261)\n",
      "Epoch gain w.r.t to objective: tensor(0.3214)\n",
      "Epoch gain w.r.t to objective: tensor(0.3165)\n",
      "Epoch gain w.r.t to objective: tensor(0.3115)\n",
      "Epoch gain w.r.t to objective: tensor(0.3064)\n",
      "Epoch gain w.r.t to objective: tensor(0.3011)\n",
      "Epoch gain w.r.t to objective: tensor(0.2957)\n",
      "Epoch gain w.r.t to objective: tensor(0.2903)\n",
      "Epoch gain w.r.t to objective: tensor(0.2848)\n",
      "Epoch gain w.r.t to objective: tensor(0.2793)\n",
      "Epoch gain w.r.t to objective: tensor(0.2737)\n",
      "Epoch gain w.r.t to objective: tensor(0.2681)\n",
      "Epoch gain w.r.t to objective: tensor(0.2626)\n",
      "Epoch gain w.r.t to objective: tensor(0.2570)\n",
      "Epoch gain w.r.t to objective: tensor(0.2515)\n",
      "Epoch gain w.r.t to objective: tensor(0.2460)\n",
      "Epoch gain w.r.t to objective: tensor(0.2406)\n",
      "Epoch gain w.r.t to objective: tensor(0.2352)\n",
      "Epoch gain w.r.t to objective: tensor(0.2300)\n",
      "Epoch gain w.r.t to objective: tensor(0.2248)\n",
      "Epoch gain w.r.t to objective: tensor(0.2197)\n",
      "Epoch gain w.r.t to objective: tensor(0.2147)\n",
      "Epoch gain w.r.t to objective: tensor(0.2098)\n",
      "Epoch gain w.r.t to objective: tensor(0.2050)\n",
      "Epoch gain w.r.t to objective: tensor(0.2004)\n",
      "Epoch gain w.r.t to objective: tensor(0.1959)\n",
      "Epoch gain w.r.t to objective: tensor(0.1915)\n",
      "Epoch gain w.r.t to objective: tensor(0.1872)\n",
      "Epoch gain w.r.t to objective: tensor(0.1830)\n",
      "Epoch gain w.r.t to objective: tensor(0.1790)\n",
      "Epoch gain w.r.t to objective: tensor(0.1752)\n",
      "Epoch gain w.r.t to objective: tensor(0.1714)\n",
      "Epoch gain w.r.t to objective: tensor(0.1678)\n",
      "Epoch gain w.r.t to objective: tensor(0.1643)\n",
      "Epoch gain w.r.t to objective: tensor(0.1609)\n",
      "Epoch gain w.r.t to objective: tensor(0.1577)\n",
      "Epoch gain w.r.t to objective: tensor(0.1546)\n",
      "Epoch gain w.r.t to objective: tensor(0.1516)\n",
      "Epoch gain w.r.t to objective: tensor(0.1488)\n",
      "Epoch gain w.r.t to objective: tensor(0.1460)\n",
      "Epoch gain w.r.t to objective: tensor(0.1434)\n",
      "Epoch gain w.r.t to objective: tensor(0.1409)\n",
      "Epoch gain w.r.t to objective: tensor(0.1384)\n",
      "Epoch gain w.r.t to objective: tensor(0.1361)\n",
      "Epoch gain w.r.t to objective: tensor(0.1339)\n",
      "Epoch gain w.r.t to objective: tensor(0.1318)\n",
      "Epoch gain w.r.t to objective: tensor(0.1297)\n",
      "Epoch gain w.r.t to objective: tensor(0.1278)\n",
      "Epoch gain w.r.t to objective: tensor(0.1259)\n",
      "Epoch gain w.r.t to objective: tensor(0.1242)\n",
      "Epoch gain w.r.t to objective: tensor(0.1224)\n",
      "Epoch gain w.r.t to objective: tensor(0.1208)\n",
      "Epoch gain w.r.t to objective: tensor(0.1192)\n",
      "Epoch gain w.r.t to objective: tensor(0.1177)\n",
      "Epoch gain w.r.t to objective: tensor(0.1163)\n",
      "Epoch gain w.r.t to objective: tensor(0.1149)\n",
      "Epoch gain w.r.t to objective: tensor(0.1136)\n",
      "Epoch gain w.r.t to objective: tensor(0.1123)\n",
      "Epoch gain w.r.t to objective: tensor(0.1111)\n",
      "Epoch gain w.r.t to objective: tensor(0.1099)\n",
      "Epoch gain w.r.t to objective: tensor(0.1088)\n",
      "Epoch gain w.r.t to objective: tensor(0.1077)\n",
      "Epoch gain w.r.t to objective: tensor(0.1067)\n",
      "Epoch gain w.r.t to objective: tensor(0.1056)\n",
      "Epoch gain w.r.t to objective: tensor(0.1047)\n",
      "Epoch gain w.r.t to objective: tensor(0.1037)\n",
      "Epoch gain w.r.t to objective: tensor(0.1028)\n",
      "Epoch gain w.r.t to objective: tensor(0.1019)\n",
      "Epoch gain w.r.t to objective: tensor(0.1010)\n",
      "Epoch gain w.r.t to objective: tensor(0.1002)\n",
      "Epoch gain w.r.t to objective: tensor(0.0994)\n",
      "Epoch gain w.r.t to objective: tensor(0.0986)\n",
      "Epoch gain w.r.t to objective: tensor(0.0978)\n",
      "Epoch gain w.r.t to objective: tensor(0.0971)\n",
      "Epoch gain w.r.t to objective: tensor(0.0963)\n",
      "Epoch gain w.r.t to objective: tensor(0.0956)\n",
      "Epoch gain w.r.t to objective: tensor(0.0949)\n",
      "Epoch gain w.r.t to objective: tensor(0.0942)\n",
      "Epoch gain w.r.t to objective: tensor(0.0936)\n",
      "Epoch gain w.r.t to objective: tensor(0.0929)\n",
      "Epoch gain w.r.t to objective: tensor(0.0923)\n",
      "Epoch gain w.r.t to objective: tensor(0.0916)\n",
      "Epoch gain w.r.t to objective: tensor(0.0910)\n",
      "Epoch gain w.r.t to objective: tensor(0.0904)\n",
      "Epoch gain w.r.t to objective: tensor(0.0898)\n",
      "Epoch gain w.r.t to objective: tensor(0.0892)\n",
      "Epoch gain w.r.t to objective: tensor(0.0886)\n",
      "Epoch gain w.r.t to objective: tensor(0.0881)\n",
      "Epoch gain w.r.t to objective: tensor(0.0875)\n",
      "Epoch gain w.r.t to objective: tensor(0.0869)\n",
      "Epoch gain w.r.t to objective: tensor(0.0864)\n",
      "Epoch gain w.r.t to objective: tensor(0.0859)\n",
      "Epoch gain w.r.t to objective: tensor(0.0853)\n",
      "Epoch gain w.r.t to objective: tensor(0.0848)\n",
      "Epoch gain w.r.t to objective: tensor(0.0843)\n",
      "Epoch gain w.r.t to objective: tensor(0.0838)\n",
      "Epoch gain w.r.t to objective: tensor(0.0833)\n",
      "Epoch gain w.r.t to objective: tensor(0.0828)\n",
      "Epoch gain w.r.t to objective: tensor(0.0823)\n",
      "Epoch gain w.r.t to objective: tensor(0.0818)\n",
      "Epoch gain w.r.t to objective: tensor(0.0814)\n",
      "Epoch gain w.r.t to objective: tensor(0.0809)\n",
      "Epoch gain w.r.t to objective: tensor(0.0804)\n",
      "Epoch gain w.r.t to objective: tensor(0.0800)\n",
      "Epoch gain w.r.t to objective: tensor(0.0795)\n",
      "Epoch gain w.r.t to objective: tensor(0.0791)\n",
      "Epoch gain w.r.t to objective: tensor(0.0787)\n",
      "Epoch gain w.r.t to objective: tensor(0.0782)\n",
      "Epoch gain w.r.t to objective: tensor(0.0778)\n",
      "Epoch gain w.r.t to objective: tensor(0.0774)\n",
      "Epoch gain w.r.t to objective: tensor(0.0770)\n",
      "Epoch gain w.r.t to objective: tensor(0.0766)\n",
      "Epoch gain w.r.t to objective: tensor(0.0762)\n",
      "Epoch gain w.r.t to objective: tensor(0.0758)\n",
      "Epoch gain w.r.t to objective: tensor(0.0754)\n",
      "Epoch gain w.r.t to objective: tensor(0.0751)\n",
      "Epoch gain w.r.t to objective: tensor(0.0747)\n",
      "Epoch gain w.r.t to objective: tensor(0.0743)\n",
      "Epoch gain w.r.t to objective: tensor(0.0740)\n",
      "Epoch gain w.r.t to objective: tensor(0.0736)\n",
      "Epoch gain w.r.t to objective: tensor(0.0732)\n",
      "Epoch gain w.r.t to objective: tensor(0.0729)\n",
      "Epoch gain w.r.t to objective: tensor(0.0725)\n",
      "Epoch gain w.r.t to objective: tensor(0.0722)\n",
      "Epoch gain w.r.t to objective: tensor(0.0718)\n",
      "Epoch gain w.r.t to objective: tensor(0.0714)\n",
      "Epoch gain w.r.t to objective: tensor(0.0711)\n",
      "Epoch gain w.r.t to objective: tensor(0.0707)\n",
      "Epoch gain w.r.t to objective: tensor(0.0703)\n",
      "Epoch gain w.r.t to objective: tensor(0.0699)\n",
      "Epoch gain w.r.t to objective: tensor(0.0696)\n",
      "Epoch gain w.r.t to objective: tensor(0.0692)\n",
      "Epoch gain w.r.t to objective: tensor(0.0688)\n",
      "Epoch gain w.r.t to objective: tensor(0.0684)\n",
      "Epoch gain w.r.t to objective: tensor(0.0679)\n",
      "Epoch gain w.r.t to objective: tensor(0.0675)\n",
      "Epoch gain w.r.t to objective: tensor(0.0671)\n",
      "Epoch gain w.r.t to objective: tensor(0.0666)\n",
      "Epoch gain w.r.t to objective: tensor(0.0662)\n",
      "Epoch gain w.r.t to objective: tensor(0.0657)\n",
      "Epoch gain w.r.t to objective: tensor(0.0652)\n",
      "Epoch gain w.r.t to objective: tensor(0.0648)\n",
      "Epoch gain w.r.t to objective: tensor(0.0643)\n",
      "Epoch gain w.r.t to objective: tensor(0.0638)\n",
      "Epoch gain w.r.t to objective: tensor(0.0634)\n",
      "Epoch gain w.r.t to objective: tensor(0.0629)\n",
      "Epoch gain w.r.t to objective: tensor(0.0624)\n",
      "Epoch gain w.r.t to objective: tensor(0.0619)\n",
      "Epoch gain w.r.t to objective: tensor(0.0615)\n",
      "Epoch gain w.r.t to objective: tensor(0.0610)\n",
      "Epoch gain w.r.t to objective: tensor(0.0605)\n",
      "Epoch gain w.r.t to objective: tensor(0.0601)\n",
      "Epoch gain w.r.t to objective: tensor(0.0596)\n",
      "Epoch gain w.r.t to objective: tensor(0.0592)\n",
      "Epoch gain w.r.t to objective: tensor(0.0587)\n",
      "Epoch gain w.r.t to objective: tensor(0.0583)\n",
      "Epoch gain w.r.t to objective: tensor(0.0578)\n",
      "Epoch gain w.r.t to objective: tensor(0.0574)\n",
      "Epoch gain w.r.t to objective: tensor(0.0570)\n",
      "Epoch gain w.r.t to objective: tensor(0.0566)\n",
      "Epoch gain w.r.t to objective: tensor(0.0561)\n",
      "Epoch gain w.r.t to objective: tensor(0.0557)\n",
      "Epoch gain w.r.t to objective: tensor(0.0553)\n",
      "Epoch gain w.r.t to objective: tensor(0.0549)\n",
      "Epoch gain w.r.t to objective: tensor(0.0545)\n",
      "Epoch gain w.r.t to objective: tensor(0.0541)\n",
      "Epoch gain w.r.t to objective: tensor(0.0537)\n",
      "Epoch gain w.r.t to objective: tensor(0.0533)\n",
      "Epoch gain w.r.t to objective: tensor(0.0529)\n",
      "Epoch gain w.r.t to objective: tensor(0.0525)\n",
      "Epoch gain w.r.t to objective: tensor(0.0521)\n",
      "Epoch gain w.r.t to objective: tensor(0.0518)\n",
      "Epoch gain w.r.t to objective: tensor(0.0514)\n",
      "Epoch gain w.r.t to objective: tensor(0.0510)\n",
      "Epoch gain w.r.t to objective: tensor(0.0506)\n",
      "Epoch gain w.r.t to objective: tensor(0.0502)\n",
      "Epoch gain w.r.t to objective: tensor(0.0498)\n",
      "Epoch gain w.r.t to objective: tensor(0.0495)\n",
      "Epoch gain w.r.t to objective: tensor(0.0491)\n",
      "Epoch gain w.r.t to objective: tensor(0.0487)\n",
      "Epoch gain w.r.t to objective: tensor(0.0483)\n",
      "Epoch gain w.r.t to objective: tensor(0.0480)\n",
      "Epoch gain w.r.t to objective: tensor(0.0476)\n",
      "Epoch gain w.r.t to objective: tensor(0.0472)\n",
      "Epoch gain w.r.t to objective: tensor(0.0469)\n",
      "Epoch gain w.r.t to objective: tensor(0.0465)\n",
      "Epoch gain w.r.t to objective: tensor(0.0461)\n",
      "Epoch gain w.r.t to objective: tensor(0.0458)\n",
      "Epoch gain w.r.t to objective: tensor(0.0454)\n",
      "Epoch gain w.r.t to objective: tensor(0.0451)\n",
      "Epoch gain w.r.t to objective: tensor(0.0447)\n",
      "Epoch gain w.r.t to objective: tensor(0.0443)\n",
      "Epoch gain w.r.t to objective: tensor(0.0440)\n",
      "Epoch gain w.r.t to objective: tensor(0.0437)\n",
      "Epoch gain w.r.t to objective: tensor(0.0433)\n",
      "Epoch gain w.r.t to objective: tensor(0.0430)\n",
      "Epoch gain w.r.t to objective: tensor(0.0427)\n",
      "Epoch gain w.r.t to objective: tensor(0.0423)\n",
      "Epoch gain w.r.t to objective: tensor(0.0420)\n",
      "Epoch gain w.r.t to objective: tensor(0.0417)\n",
      "Epoch gain w.r.t to objective: tensor(0.0414)\n",
      "Epoch gain w.r.t to objective: tensor(0.0411)\n",
      "Epoch gain w.r.t to objective: tensor(0.0408)\n",
      "Epoch gain w.r.t to objective: tensor(0.0405)\n",
      "Epoch gain w.r.t to objective: tensor(0.0402)\n",
      "Epoch gain w.r.t to objective: tensor(0.0399)\n",
      "Epoch gain w.r.t to objective: tensor(0.0396)\n",
      "Epoch gain w.r.t to objective: tensor(0.0394)\n",
      "Epoch gain w.r.t to objective: tensor(0.0391)\n",
      "Epoch gain w.r.t to objective: tensor(0.0389)\n",
      "Epoch gain w.r.t to objective: tensor(0.0386)\n",
      "Epoch gain w.r.t to objective: tensor(0.0384)\n",
      "Epoch gain w.r.t to objective: tensor(0.0382)\n",
      "Epoch gain w.r.t to objective: tensor(0.0380)\n",
      "Epoch gain w.r.t to objective: tensor(0.0378)\n",
      "Epoch gain w.r.t to objective: tensor(0.0376)\n",
      "Epoch gain w.r.t to objective: tensor(0.0375)\n",
      "Epoch gain w.r.t to objective: tensor(0.0373)\n",
      "Epoch gain w.r.t to objective: tensor(0.0371)\n",
      "Epoch gain w.r.t to objective: tensor(0.0370)\n",
      "Epoch gain w.r.t to objective: tensor(0.0369)\n",
      "Epoch gain w.r.t to objective: tensor(0.0368)\n",
      "Epoch gain w.r.t to objective: tensor(0.0367)\n",
      "Epoch gain w.r.t to objective: tensor(0.0366)\n",
      "Epoch gain w.r.t to objective: tensor(0.0365)\n",
      "Epoch gain w.r.t to objective: tensor(0.0365)\n",
      "Epoch gain w.r.t to objective: tensor(0.0364)\n",
      "Epoch gain w.r.t to objective: tensor(0.0364)\n",
      "Epoch gain w.r.t to objective: tensor(0.0364)\n",
      "Epoch gain w.r.t to objective: tensor(0.0364)\n",
      "Epoch gain w.r.t to objective: tensor(0.0364)\n",
      "Epoch gain w.r.t to objective: tensor(0.0364)\n",
      "Epoch gain w.r.t to objective: tensor(0.0364)\n",
      "Epoch gain w.r.t to objective: tensor(0.0364)\n",
      "Epoch gain w.r.t to objective: tensor(0.0364)\n",
      "Epoch gain w.r.t to objective: tensor(0.0365)\n",
      "Epoch gain w.r.t to objective: tensor(0.0365)\n",
      "Epoch gain w.r.t to objective: tensor(0.0366)\n",
      "Epoch gain w.r.t to objective: tensor(0.0366)\n",
      "Epoch gain w.r.t to objective: tensor(0.0367)\n",
      "Epoch gain w.r.t to objective: tensor(0.0367)\n",
      "Epoch gain w.r.t to objective: tensor(0.0368)\n",
      "Epoch gain w.r.t to objective: tensor(0.0368)\n",
      "Epoch gain w.r.t to objective: tensor(0.0369)\n",
      "Epoch gain w.r.t to objective: tensor(0.0369)\n",
      "Epoch gain w.r.t to objective: tensor(0.0369)\n",
      "Epoch gain w.r.t to objective: tensor(0.0369)\n",
      "Epoch gain w.r.t to objective: tensor(0.0370)\n",
      "Epoch gain w.r.t to objective: tensor(0.0370)\n",
      "Epoch gain w.r.t to objective: tensor(0.0369)\n",
      "Epoch gain w.r.t to objective: tensor(0.0369)\n",
      "Epoch gain w.r.t to objective: tensor(0.0369)\n",
      "Epoch gain w.r.t to objective: tensor(0.0368)\n",
      "Epoch gain w.r.t to objective: tensor(0.0367)\n",
      "Epoch gain w.r.t to objective: tensor(0.0366)\n",
      "Epoch gain w.r.t to objective: tensor(0.0365)\n",
      "Epoch gain w.r.t to objective: tensor(0.0364)\n",
      "Epoch gain w.r.t to objective: tensor(0.0363)\n",
      "Epoch gain w.r.t to objective: tensor(0.0361)\n",
      "Epoch gain w.r.t to objective: tensor(0.0359)\n",
      "Epoch gain w.r.t to objective: tensor(0.0357)\n",
      "Epoch gain w.r.t to objective: tensor(0.0355)\n",
      "Epoch gain w.r.t to objective: tensor(0.0353)\n",
      "Epoch gain w.r.t to objective: tensor(0.0350)\n",
      "Epoch gain w.r.t to objective: tensor(0.0347)\n",
      "Epoch gain w.r.t to objective: tensor(0.0344)\n",
      "Epoch gain w.r.t to objective: tensor(0.0341)\n",
      "Epoch gain w.r.t to objective: tensor(0.0338)\n",
      "Epoch gain w.r.t to objective: tensor(0.0335)\n",
      "Epoch gain w.r.t to objective: tensor(0.0332)\n",
      "Epoch gain w.r.t to objective: tensor(0.0328)\n",
      "Epoch gain w.r.t to objective: tensor(0.0325)\n",
      "Epoch gain w.r.t to objective: tensor(0.0321)\n",
      "Epoch gain w.r.t to objective: tensor(0.0317)\n",
      "Epoch gain w.r.t to objective: tensor(0.0313)\n",
      "Epoch gain w.r.t to objective: tensor(0.0310)\n",
      "Epoch gain w.r.t to objective: tensor(0.0306)\n",
      "Epoch gain w.r.t to objective: tensor(0.0302)\n",
      "Epoch gain w.r.t to objective: tensor(0.0298)\n",
      "Epoch gain w.r.t to objective: tensor(0.0294)\n",
      "Epoch gain w.r.t to objective: tensor(0.0290)\n",
      "Epoch gain w.r.t to objective: tensor(0.0286)\n",
      "Epoch gain w.r.t to objective: tensor(0.0282)\n",
      "Epoch gain w.r.t to objective: tensor(0.0278)\n",
      "Epoch gain w.r.t to objective: tensor(0.0274)\n",
      "Epoch gain w.r.t to objective: tensor(0.0270)\n",
      "Epoch gain w.r.t to objective: tensor(0.0266)\n",
      "Epoch gain w.r.t to objective: tensor(0.0262)\n",
      "Epoch gain w.r.t to objective: tensor(0.0259)\n",
      "Epoch gain w.r.t to objective: tensor(0.0255)\n",
      "Epoch gain w.r.t to objective: tensor(0.0251)\n",
      "Epoch gain w.r.t to objective: tensor(0.0247)\n",
      "Epoch gain w.r.t to objective: tensor(0.0244)\n",
      "Epoch gain w.r.t to objective: tensor(0.0240)\n",
      "Epoch gain w.r.t to objective: tensor(0.0237)\n",
      "Epoch gain w.r.t to objective: tensor(0.0233)\n",
      "Epoch gain w.r.t to objective: tensor(0.0230)\n",
      "Epoch gain w.r.t to objective: tensor(0.0226)\n",
      "Epoch gain w.r.t to objective: tensor(0.0223)\n",
      "Epoch gain w.r.t to objective: tensor(0.0219)\n",
      "Epoch gain w.r.t to objective: tensor(0.0216)\n",
      "Epoch gain w.r.t to objective: tensor(0.0213)\n",
      "Epoch gain w.r.t to objective: tensor(0.0209)\n",
      "Epoch gain w.r.t to objective: tensor(0.0206)\n",
      "Epoch gain w.r.t to objective: tensor(0.0203)\n",
      "Epoch gain w.r.t to objective: tensor(0.0200)\n",
      "Epoch gain w.r.t to objective: tensor(0.0197)\n",
      "Epoch gain w.r.t to objective: tensor(0.0194)\n",
      "Epoch gain w.r.t to objective: tensor(0.0191)\n",
      "Epoch gain w.r.t to objective: tensor(0.0188)\n",
      "Epoch gain w.r.t to objective: tensor(0.0185)\n",
      "Epoch gain w.r.t to objective: tensor(0.0182)\n",
      "Epoch gain w.r.t to objective: tensor(0.0179)\n",
      "Epoch gain w.r.t to objective: tensor(0.0176)\n",
      "Epoch gain w.r.t to objective: tensor(0.0173)\n",
      "Epoch gain w.r.t to objective: tensor(0.0170)\n",
      "Epoch gain w.r.t to objective: tensor(0.0168)\n",
      "Epoch gain w.r.t to objective: tensor(0.0165)\n",
      "Epoch gain w.r.t to objective: tensor(0.0162)\n",
      "Epoch gain w.r.t to objective: tensor(0.0159)\n",
      "Epoch gain w.r.t to objective: tensor(0.0156)\n",
      "Epoch gain w.r.t to objective: tensor(0.0154)\n",
      "Epoch gain w.r.t to objective: tensor(0.0151)\n",
      "Epoch gain w.r.t to objective: tensor(0.0148)\n",
      "Epoch gain w.r.t to objective: tensor(0.0145)\n",
      "Epoch gain w.r.t to objective: tensor(0.0143)\n",
      "Epoch gain w.r.t to objective: tensor(0.0140)\n",
      "Epoch gain w.r.t to objective: tensor(0.0137)\n",
      "Epoch gain w.r.t to objective: tensor(0.0135)\n",
      "Epoch gain w.r.t to objective: tensor(0.0132)\n",
      "Epoch gain w.r.t to objective: tensor(0.0129)\n",
      "Epoch gain w.r.t to objective: tensor(0.0127)\n",
      "Epoch gain w.r.t to objective: tensor(0.0124)\n",
      "Epoch gain w.r.t to objective: tensor(0.0121)\n",
      "Epoch gain w.r.t to objective: tensor(0.0119)\n",
      "Epoch gain w.r.t to objective: tensor(0.0116)\n",
      "Epoch gain w.r.t to objective: tensor(0.0113)\n",
      "Epoch gain w.r.t to objective: tensor(0.0111)\n",
      "Epoch gain w.r.t to objective: tensor(0.0108)\n",
      "Epoch gain w.r.t to objective: tensor(0.0106)\n",
      "Epoch gain w.r.t to objective: tensor(0.0103)\n",
      "Epoch gain w.r.t to objective: tensor(0.0100)\n",
      "Epoch gain w.r.t to objective: tensor(0.0098)\n",
      "Epoch gain w.r.t to objective: tensor(0.0095)\n",
      "Epoch gain w.r.t to objective: tensor(0.0093)\n",
      "Epoch gain w.r.t to objective: tensor(0.0090)\n",
      "Epoch gain w.r.t to objective: tensor(0.0087)\n",
      "Epoch gain w.r.t to objective: tensor(0.0085)\n",
      "Epoch gain w.r.t to objective: tensor(0.0083)\n",
      "Epoch gain w.r.t to objective: tensor(0.0080)\n",
      "Epoch gain w.r.t to objective: tensor(0.0078)\n",
      "Epoch gain w.r.t to objective: tensor(0.0075)\n",
      "Epoch gain w.r.t to objective: tensor(0.0073)\n",
      "Epoch gain w.r.t to objective: tensor(0.0071)\n",
      "Epoch gain w.r.t to objective: tensor(0.0069)\n",
      "Epoch gain w.r.t to objective: tensor(0.0066)\n",
      "Epoch gain w.r.t to objective: tensor(0.0064)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0060)\n",
      "Epoch gain w.r.t to objective: tensor(0.0059)\n",
      "Epoch gain w.r.t to objective: tensor(0.0057)\n",
      "Epoch gain w.r.t to objective: tensor(0.0055)\n",
      "Epoch gain w.r.t to objective: tensor(0.0054)\n",
      "Epoch gain w.r.t to objective: tensor(0.0052)\n",
      "Epoch gain w.r.t to objective: tensor(0.0051)\n",
      "Epoch gain w.r.t to objective: tensor(0.0050)\n",
      "Epoch gain w.r.t to objective: tensor(0.0049)\n",
      "Epoch gain w.r.t to objective: tensor(0.0048)\n",
      "Epoch gain w.r.t to objective: tensor(0.0047)\n",
      "Epoch gain w.r.t to objective: tensor(0.0046)\n",
      "Epoch gain w.r.t to objective: tensor(0.0045)\n",
      "Epoch gain w.r.t to objective: tensor(0.0045)\n",
      "Epoch gain w.r.t to objective: tensor(0.0045)\n",
      "Epoch gain w.r.t to objective: tensor(0.0044)\n",
      "Epoch gain w.r.t to objective: tensor(0.0044)\n",
      "Epoch gain w.r.t to objective: tensor(0.0044)\n",
      "Epoch gain w.r.t to objective: tensor(0.0044)\n",
      "Epoch gain w.r.t to objective: tensor(0.0044)\n",
      "Epoch gain w.r.t to objective: tensor(0.0044)\n",
      "Epoch gain w.r.t to objective: tensor(0.0045)\n",
      "Epoch gain w.r.t to objective: tensor(0.0045)\n",
      "Epoch gain w.r.t to objective: tensor(0.0045)\n",
      "Epoch gain w.r.t to objective: tensor(0.0046)\n",
      "Epoch gain w.r.t to objective: tensor(0.0046)\n",
      "Epoch gain w.r.t to objective: tensor(0.0047)\n",
      "Epoch gain w.r.t to objective: tensor(0.0048)\n",
      "Epoch gain w.r.t to objective: tensor(0.0048)\n",
      "Epoch gain w.r.t to objective: tensor(0.0049)\n",
      "Epoch gain w.r.t to objective: tensor(0.0050)\n",
      "Epoch gain w.r.t to objective: tensor(0.0050)\n",
      "Epoch gain w.r.t to objective: tensor(0.0051)\n",
      "Epoch gain w.r.t to objective: tensor(0.0052)\n",
      "Epoch gain w.r.t to objective: tensor(0.0053)\n",
      "Epoch gain w.r.t to objective: tensor(0.0053)\n",
      "Epoch gain w.r.t to objective: tensor(0.0054)\n",
      "Epoch gain w.r.t to objective: tensor(0.0055)\n",
      "Epoch gain w.r.t to objective: tensor(0.0055)\n",
      "Epoch gain w.r.t to objective: tensor(0.0056)\n",
      "Epoch gain w.r.t to objective: tensor(0.0057)\n",
      "Epoch gain w.r.t to objective: tensor(0.0057)\n",
      "Epoch gain w.r.t to objective: tensor(0.0058)\n",
      "Epoch gain w.r.t to objective: tensor(0.0058)\n",
      "Epoch gain w.r.t to objective: tensor(0.0059)\n",
      "Epoch gain w.r.t to objective: tensor(0.0059)\n",
      "Epoch gain w.r.t to objective: tensor(0.0060)\n",
      "Epoch gain w.r.t to objective: tensor(0.0060)\n",
      "Epoch gain w.r.t to objective: tensor(0.0060)\n",
      "Epoch gain w.r.t to objective: tensor(0.0061)\n",
      "Epoch gain w.r.t to objective: tensor(0.0061)\n",
      "Epoch gain w.r.t to objective: tensor(0.0061)\n",
      "Epoch gain w.r.t to objective: tensor(0.0061)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0062)\n",
      "Epoch gain w.r.t to objective: tensor(0.0061)\n",
      "Epoch gain w.r.t to objective: tensor(0.0061)\n",
      "Epoch gain w.r.t to objective: tensor(0.0061)\n",
      "Epoch gain w.r.t to objective: tensor(0.0061)\n",
      "Epoch gain w.r.t to objective: tensor(0.0061)\n",
      "Epoch gain w.r.t to objective: tensor(0.0061)\n",
      "Epoch gain w.r.t to objective: tensor(0.0060)\n",
      "Epoch gain w.r.t to objective: tensor(0.0060)\n",
      "Epoch gain w.r.t to objective: tensor(0.0060)\n",
      "Epoch gain w.r.t to objective: tensor(0.0060)\n",
      "Epoch gain w.r.t to objective: tensor(0.0059)\n",
      "Epoch gain w.r.t to objective: tensor(0.0059)\n",
      "Epoch gain w.r.t to objective: tensor(0.0059)\n",
      "Epoch gain w.r.t to objective: tensor(0.0059)\n",
      "Epoch gain w.r.t to objective: tensor(0.0059)\n",
      "Epoch gain w.r.t to objective: tensor(0.0058)\n",
      "Epoch gain w.r.t to objective: tensor(0.0058)\n",
      "Epoch gain w.r.t to objective: tensor(0.0058)\n",
      "Epoch gain w.r.t to objective: tensor(0.0057)\n",
      "Epoch gain w.r.t to objective: tensor(0.0057)\n",
      "Epoch gain w.r.t to objective: tensor(0.0057)\n",
      "Epoch gain w.r.t to objective: tensor(0.0057)\n",
      "Epoch gain w.r.t to objective: tensor(0.0056)\n",
      "Epoch gain w.r.t to objective: tensor(0.0056)\n",
      "Epoch gain w.r.t to objective: tensor(0.0056)\n",
      "Epoch gain w.r.t to objective: tensor(0.0056)\n",
      "Epoch gain w.r.t to objective: tensor(0.0055)\n",
      "Epoch gain w.r.t to objective: tensor(0.0055)\n",
      "Epoch gain w.r.t to objective: tensor(0.0055)\n",
      "Epoch gain w.r.t to objective: tensor(0.0054)\n",
      "Epoch gain w.r.t to objective: tensor(0.0054)\n",
      "Epoch gain w.r.t to objective: tensor(0.0054)\n",
      "Epoch gain w.r.t to objective: tensor(0.0054)\n",
      "Epoch gain w.r.t to objective: tensor(0.0053)\n",
      "Epoch gain w.r.t to objective: tensor(0.0053)\n",
      "Epoch gain w.r.t to objective: tensor(0.0053)\n",
      "Epoch gain w.r.t to objective: tensor(0.0053)\n",
      "Epoch gain w.r.t to objective: tensor(0.0052)\n",
      "Epoch gain w.r.t to objective: tensor(0.0052)\n",
      "Epoch gain w.r.t to objective: tensor(0.0052)\n",
      "Epoch gain w.r.t to objective: tensor(0.0051)\n",
      "Epoch gain w.r.t to objective: tensor(0.0051)\n",
      "Epoch gain w.r.t to objective: tensor(0.0051)\n",
      "Epoch gain w.r.t to objective: tensor(0.0051)\n",
      "Epoch gain w.r.t to objective: tensor(0.0050)\n",
      "Epoch gain w.r.t to objective: tensor(0.0050)\n",
      "Epoch gain w.r.t to objective: tensor(0.0050)\n",
      "Epoch gain w.r.t to objective: tensor(0.0050)\n",
      "Epoch gain w.r.t to objective: tensor(0.0049)\n",
      "Epoch gain w.r.t to objective: tensor(0.0049)\n",
      "Epoch gain w.r.t to objective: tensor(0.0049)\n",
      "Epoch gain w.r.t to objective: tensor(0.0049)\n",
      "Epoch gain w.r.t to objective: tensor(0.0048)\n",
      "Epoch gain w.r.t to objective: tensor(0.0048)\n",
      "Epoch gain w.r.t to objective: tensor(0.0048)\n",
      "Epoch gain w.r.t to objective: tensor(0.0048)\n",
      "Epoch gain w.r.t to objective: tensor(0.0047)\n",
      "Epoch gain w.r.t to objective: tensor(0.0047)\n",
      "Epoch gain w.r.t to objective: tensor(0.0047)\n",
      "Epoch gain w.r.t to objective: tensor(0.0047)\n",
      "Epoch gain w.r.t to objective: tensor(0.0046)\n",
      "Epoch gain w.r.t to objective: tensor(0.0046)\n",
      "Epoch gain w.r.t to objective: tensor(0.0046)\n",
      "Epoch gain w.r.t to objective: tensor(0.0046)\n",
      "Epoch gain w.r.t to objective: tensor(0.0045)\n",
      "Epoch gain w.r.t to objective: tensor(0.0045)\n",
      "Epoch gain w.r.t to objective: tensor(0.0045)\n",
      "Epoch gain w.r.t to objective: tensor(0.0045)\n",
      "Epoch gain w.r.t to objective: tensor(0.0045)\n",
      "Epoch gain w.r.t to objective: tensor(0.0044)\n",
      "Epoch gain w.r.t to objective: tensor(0.0044)\n",
      "Epoch gain w.r.t to objective: tensor(0.0044)\n",
      "Epoch gain w.r.t to objective: tensor(0.0044)\n",
      "Epoch gain w.r.t to objective: tensor(0.0044)\n",
      "Epoch gain w.r.t to objective: tensor(0.0044)\n",
      "Epoch gain w.r.t to objective: tensor(0.0043)\n",
      "Epoch gain w.r.t to objective: tensor(0.0043)\n",
      "Epoch gain w.r.t to objective: tensor(0.0043)\n",
      "Epoch gain w.r.t to objective: tensor(0.0043)\n",
      "Epoch gain w.r.t to objective: tensor(0.0043)\n",
      "Epoch gain w.r.t to objective: tensor(0.0043)\n",
      "Epoch gain w.r.t to objective: tensor(0.0042)\n",
      "Epoch gain w.r.t to objective: tensor(0.0042)\n",
      "Epoch gain w.r.t to objective: tensor(0.0042)\n",
      "Epoch gain w.r.t to objective: tensor(0.0042)\n",
      "Epoch gain w.r.t to objective: tensor(0.0042)\n",
      "Epoch gain w.r.t to objective: tensor(0.0042)\n",
      "Epoch gain w.r.t to objective: tensor(0.0041)\n",
      "Epoch gain w.r.t to objective: tensor(0.0041)\n",
      "Epoch gain w.r.t to objective: tensor(0.0041)\n",
      "Epoch gain w.r.t to objective: tensor(0.0041)\n",
      "Epoch gain w.r.t to objective: tensor(0.0041)\n",
      "Epoch gain w.r.t to objective: tensor(0.0041)\n",
      "Epoch gain w.r.t to objective: tensor(0.0041)\n",
      "Epoch gain w.r.t to objective: tensor(0.0040)\n",
      "Epoch gain w.r.t to objective: tensor(0.0040)\n",
      "Epoch gain w.r.t to objective: tensor(0.0040)\n",
      "Epoch gain w.r.t to objective: tensor(0.0040)\n",
      "Epoch gain w.r.t to objective: tensor(0.0040)\n",
      "Epoch gain w.r.t to objective: tensor(0.0039)\n",
      "Epoch gain w.r.t to objective: tensor(0.0039)\n",
      "Epoch gain w.r.t to objective: tensor(0.0039)\n",
      "Epoch gain w.r.t to objective: tensor(0.0038)\n",
      "Epoch gain w.r.t to objective: tensor(0.0038)\n",
      "Epoch gain w.r.t to objective: tensor(0.0038)\n",
      "Epoch gain w.r.t to objective: tensor(0.0037)\n",
      "Epoch gain w.r.t to objective: tensor(0.0036)\n",
      "Epoch gain w.r.t to objective: tensor(0.0036)\n",
      "Epoch gain w.r.t to objective: tensor(0.0035)\n",
      "Epoch gain w.r.t to objective: tensor(0.0034)\n",
      "Epoch gain w.r.t to objective: tensor(0.0033)\n",
      "Epoch gain w.r.t to objective: tensor(0.0032)\n",
      "Epoch gain w.r.t to objective: tensor(0.0031)\n",
      "Epoch gain w.r.t to objective: tensor(0.0030)\n",
      "Epoch gain w.r.t to objective: tensor(0.0028)\n",
      "Epoch gain w.r.t to objective: tensor(0.0027)\n",
      "Epoch gain w.r.t to objective: tensor(0.0025)\n",
      "Epoch gain w.r.t to objective: tensor(0.0024)\n",
      "Epoch gain w.r.t to objective: tensor(0.0022)\n",
      "Epoch gain w.r.t to objective: tensor(0.0020)\n",
      "Epoch gain w.r.t to objective: tensor(0.0018)\n",
      "Epoch gain w.r.t to objective: tensor(0.0016)\n",
      "Epoch gain w.r.t to objective: tensor(0.0014)\n",
      "Epoch gain w.r.t to objective: tensor(0.0012)\n",
      "Epoch gain w.r.t to objective: tensor(0.0010)\n",
      "Epoch gain w.r.t to objective: tensor(0.0008)\n"
     ]
    }
   ],
   "source": [
    "hmm = LinearGaussianHMM(state_dim=2, obs_dim=2) # pick some true p p \n",
    "for param in hmm.model.parameters(): param.requires_grad = False # not learning the parameters of the true p for now \n",
    "\n",
    "\n",
    "\n",
    "# sampling 10 sequences from the hmm \n",
    "samples = [hmm.sample_joint_sequence(8) for _ in range(10)] \n",
    "state_sequences = [sample[0] for sample in samples]\n",
    "observation_sequences = [sample[1] for sample in samples] \n",
    "\n",
    "\n",
    "# the variational p is a random LGMM with same dimensions, and we will not learn the covariances for now\n",
    "q = LinearGaussianHMM.get_random_model(2,2)\n",
    "q.prior.parametrizations.cov.original.requires_grad = False\n",
    "q.transition.parametrizations.cov.original.requires_grad = False \n",
    "q.emission.parametrizations.cov.original.requires_grad = False \n",
    "\n",
    "# the elbo object with p and q as arguments\n",
    "elbo = fully_linear_gaussian_elbo(hmm.model, q)\n",
    "\n",
    "# optimize the parameters of the ELBO (but theta deactivated above)\n",
    "optimizer = torch.optim.Adam(params=elbo.parameters(), lr=1e-2)\n",
    "true_evidence_all_sequences = sum(Kalman(hmm.model).filter(observations)[-1] for observations in observation_sequences)\n",
    "\n",
    "print('True evidence accross all sequences:', true_evidence_all_sequences)\n",
    "\n",
    "# optimizing p \n",
    "distance_to_true_objective = torch.abs(true_evidence_all_sequences - torch.inf)\n",
    "eps = distance_to_true_objective\n",
    "\n",
    "while eps > 1e-3:\n",
    "    epoch_loss = 0.0\n",
    "    for observations in observation_sequences: \n",
    "        optimizer.zero_grad()\n",
    "        loss = -elbo(observations)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += -loss\n",
    "    with torch.no_grad():\n",
    "        new_distance_true_objective = torch.abs(true_evidence_all_sequences - epoch_loss)\n",
    "        eps = torch.abs(new_distance_true_objective - distance_to_true_objective)\n",
    "        distance_to_true_objective = new_distance_true_objective\n",
    "        print('Epoch gain w.r.t to objective:', eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE when smoothed with p: tensor(0.0079)\n",
      "MSE when smoothed with q: tensor(0.0112)\n"
     ]
    }
   ],
   "source": [
    "# checking expectations under approximate p when the additive functional is just the sum \n",
    "with torch.no_grad():\n",
    "    additive_functional = partial(torch.sum, dim=0)\n",
    "    smoothed_with_true_model = mse_expectation_against_true_states(state_sequences, observation_sequences, hmm.model, additive_functional)\n",
    "    smoothed_with_approximate_model = mse_expectation_against_true_states(state_sequences, observation_sequences, q, additive_functional)\n",
    "\n",
    "    print('MSE when smoothed with p:',smoothed_with_true_model)\n",
    "    print('MSE when smoothed with q:',smoothed_with_approximate_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. b. Using a neural network to compute the backward parameters instead of Kalman recursions\n",
    "We make the same assumptions on $p_\\theta$ but now we attempt to recover the backward parameters via neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A nonlinear emission p\n",
    "\n",
    "We now assume that $p_\\theta$ has a nonlinear emission distribution, ie. $x_t  = f_\\theta(z_t) + \\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. a. Approximated by a linear Gaussian p.\n",
    "We keep a linear gaussian distribution for $q_\\phi$, but we add a mapping to compute the expectation of the emission term from $p_\\theta$. We need to approximate the following quantity:\n",
    "\n",
    "$$\\mathbb{E}_{q(z_t|z_{t+1}, x_{1:t})}\\left[(x_t - f_\\theta(z_t))^T R^{{\\theta}^{-1}}(x_t - f_\\theta(z_t))\\right]$$\n",
    "\n",
    "And similarly for the last expectation under the filtering distribution: \n",
    "\n",
    "$$\\mathbb{E}_{q(z_T|x_{1:T})}\\left[(x_T - f_\\theta(z_T))^T R^{{\\theta}^{-1}}(x_T - f_\\theta(z_T))\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. a. i. A sampling-free approach. \n",
    "\n",
    "\n",
    "If we know the expectation $\\mu$ and variance $\\Sigma$ of a random variable $v$ (which need not be Gaussian):\n",
    "\n",
    "$$\\mathbb{E}_{v}\\left[(x - v)^T \\Omega (x - v)\\right] = tr(\\Sigma \\Omega) + (\\mu - x)^T \\Omega (\\mu - x)$$\n",
    "\n",
    "Suppose we a have neural network which approximates the mean and variance of $v \\sim f_\\theta(z)$ when $z \\sim p_z$, given parameters of $p_z$. Denote $\\tilde{\\mu}$ and $\\tilde{\\Sigma}$ these means and variances estimated by this network. For the filtering case, we feed the network with filtering mean and covariance at $T$ to obtain an estimate of $\\tilde{\\mu}$ and $\\tilde{\\Sigma}$, then:\n",
    "\n",
    "$$\\mathbb{E}_{q(z_T|x_{1:T})}\\left[(x_T - f_\\theta(z_T))^T R^{{\\theta}^{-1}}(x_T - f_\\theta(z_T))\\right] = tr(\\tilde{\\Sigma} \\Omega) + (\\tilde{\\mu} - x)^T R^{{\\theta}^{-1}} (\\tilde{\\mu} - x)$$\n",
    "\n",
    "For the backwards case this is not as simple, because: $\\overleftarrow{\\mu}_{1:t}$ is a function of $z_{t+1}$, therefore $\\mathbb{E}_{q(z_t|z_{t+1}, x_{1:t})}[f_\\theta(z_t)]$ and $\\mathbb{V}_{q(z_t|z_{t+1}, x_{1:t})}[f_\\theta(z_t)]$ are also functions of $z_{t+1}$. \n",
    "\n",
    "We still attempt to use one network for both the fitlering and the backwards via the following scheme: \n",
    "\n",
    "- Build a neural network $g_\\alpha(A, a, \\Sigma)$ which outputs $\\tilde{A}, \\tilde{a}$ and $\\tilde{\\Sigma}$\n",
    "- For the backwards case, use $A = \\overleftarrow{A}_{1:t}, a = \\overleftarrow{a}_{1:t}$ and $\\Sigma = \\overleftarrow{\\Sigma}_{1:t}$, and consider that $\\tilde{\\mu} = \\tilde{A}z_{t+1} + \\tilde{a}$, while $\\tilde{\\Sigma}$ does not depend on $z_{t+1}$ (which is knowingly false). In this case, the quadratic form build for $\\tilde{A}$ and $\\tilde{a}$ is a quadratic form in $z_{t+1}$ as wanted.\n",
    "- For the backwards case, use $A = 0, a = a_{1:t}$ and $\\Sigma = \\Sigma_{1:t}$, and consider that $\\tilde{\\mu} = \\tilde{a}$ (without using the output $\\tilde{A}$).\n",
    "\n",
    "*This method, which is tried below: fails to learn anything as of now.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_quad_form_in_emission_term() missing 1 required positional argument: 'z'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/infres/chagneux/repos/backward_ica/demos.ipynb Cell 15'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/home/infres/chagneux/repos/backward_ica/demos.ipynb#ch0000014vscode-remote?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m observations \u001b[39min\u001b[39;00m observation_sequences: \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/home/infres/chagneux/repos/backward_ica/demos.ipynb#ch0000014vscode-remote?line=32'>33</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/home/infres/chagneux/repos/backward_ica/demos.ipynb#ch0000014vscode-remote?line=33'>34</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39melbo(observations)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/home/infres/chagneux/repos/backward_ica/demos.ipynb#ch0000014vscode-remote?line=34'>35</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu2/home/infres/chagneux/repos/backward_ica/demos.ipynb#ch0000014vscode-remote?line=35'>36</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/repos/backward_ica/src/elbo.py:137\u001b[0m, in \u001b[0;36mBackwardELBO.forward\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=133'>134</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit(observations[\u001b[39m0\u001b[39m])\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=135'>136</a>\u001b[0m \u001b[39mfor\u001b[39;00m observation \u001b[39min\u001b[39;00m observations[\u001b[39m1\u001b[39m:]:\n\u001b[0;32m--> <a href='file:///~/repos/backward_ica/src/elbo.py?line=136'>137</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update(observation)\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=137'>138</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstants_V \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39m_constant_terms_from_log_gaussian(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_z, torch\u001b[39m.\u001b[39mdet(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiltering_params\u001b[39m.\u001b[39mcov))\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=139'>140</a>\u001b[0m result \u001b[39m=\u001b[39m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expect_V_under_filtering()\n",
      "File \u001b[0;32m~/repos/backward_ica/src/elbo.py:114\u001b[0m, in \u001b[0;36mBackwardELBO._update\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=111'>112</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_backward()\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=112'>113</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_filtering(observation)\n\u001b[0;32m--> <a href='file:///~/repos/backward_ica/src/elbo.py?line=113'>114</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_V(observation)\n",
      "File \u001b[0;32m~/repos/backward_ica/src/elbo.py:186\u001b[0m, in \u001b[0;36mLinearGaussianQ._update_V\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=182'>183</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_V\u001b[39m(\u001b[39mself\u001b[39m, observation):\n\u001b[0;32m--> <a href='file:///~/repos/backward_ica/src/elbo.py?line=185'>186</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_integrate_previous_terms()\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=187'>188</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstants_V \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m _constant_terms_from_log_gaussian(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp_emission_det_cov) \\\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=188'>189</a>\u001b[0m                     \u001b[39m+\u001b[39m  _constant_terms_from_log_gaussian(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_z, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp_transition_det_cov) \\\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=189'>190</a>\u001b[0m                     \u001b[39m+\u001b[39m \u001b[39m-\u001b[39m_constant_terms_from_log_gaussian(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_z, torch\u001b[39m.\u001b[39mdet(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward_params\u001b[39m.\u001b[39mcov)) \\\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=190'>191</a>\u001b[0m                     \u001b[39m+\u001b[39m  \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_z, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat64) \\\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=191'>192</a>\u001b[0m                     \u001b[39m+\u001b[39m \u001b[39m-\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mtrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp_transition_prec \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp\u001b[39m.\u001b[39mtransition\u001b[39m.\u001b[39mmap\u001b[39m.\u001b[39mweight \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward_params\u001b[39m.\u001b[39mcov \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp\u001b[39m.\u001b[39mtransition\u001b[39m.\u001b[39mmap\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mT)\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=193'>194</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransition_terms\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expect_transition_quad_form_under_backward())\n",
      "File \u001b[0;32m~/repos/backward_ica/src/elbo.py:180\u001b[0m, in \u001b[0;36mLinearGaussianQ._integrate_previous_terms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=177'>178</a>\u001b[0m \u001b[39mfor\u001b[39;00m term_nb, (transition_term, obs_term) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransition_terms, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_terms)):\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=178'>179</a>\u001b[0m     constants_0, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransition_terms[term_nb] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expect_quad_form_under_backward(transition_term)\n\u001b[0;32m--> <a href='file:///~/repos/backward_ica/src/elbo.py?line=179'>180</a>\u001b[0m     constants_1, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_terms[term_nb] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_expect_obs_term_under_backward(obs_term)\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=180'>181</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstants_V \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m constants_0 \u001b[39m+\u001b[39m constants_1\n",
      "File \u001b[0;32m~/repos/backward_ica/src/elbo.py:274\u001b[0m, in \u001b[0;36mNonLinearEmission._expect_obs_term_under_backward\u001b[0;34m(self, obs_term)\u001b[0m\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=271'>272</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_expect_obs_term_under_backward\u001b[39m(\u001b[39mself\u001b[39m, obs_term):\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=272'>273</a>\u001b[0m     observation \u001b[39m=\u001b[39m obs_term\n\u001b[0;32m--> <a href='file:///~/repos/backward_ica/src/elbo.py?line=273'>274</a>\u001b[0m     nonlinear_map \u001b[39m=\u001b[39m partial(_quad_form_in_emission_term(observation\u001b[39m=\u001b[39;49mobservation, \n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=274'>275</a>\u001b[0m                                                         emission_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp\u001b[39m.\u001b[39;49memission\u001b[39m.\u001b[39;49mmap, \n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=275'>276</a>\u001b[0m                                                         emission_prec\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp_emission_prec))\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=277'>278</a>\u001b[0m     v, W \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapproximator(filtering_params\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiltering_params, \n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=278'>279</a>\u001b[0m                             backward_params\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward_params, \n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=279'>280</a>\u001b[0m                             nonlinear_map\u001b[39m=\u001b[39mnonlinear_map)\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=281'>282</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m QuadForm(Omega\u001b[39m=\u001b[39mW, \n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=282'>283</a>\u001b[0m                     A\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39meye(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_x),\n\u001b[1;32m    <a href='file:///~/repos/backward_ica/src/elbo.py?line=283'>284</a>\u001b[0m                     b\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mv)\n",
      "\u001b[0;31mTypeError\u001b[0m: _quad_form_in_emission_term() missing 1 required positional argument: 'z'"
     ]
    }
   ],
   "source": [
    "hmm = AdditiveGaussianHMM(state_dim=2, obs_dim=2) # we now take an hmm wih \n",
    "\n",
    "# sampling 10 sequences from the hmm \n",
    "samples = [hmm.sample_joint_sequence(8) for _ in range(10)] \n",
    "state_sequences = [sample[0] for sample in samples]\n",
    "observation_sequences = [sample[1] for sample in samples] \n",
    "\n",
    "\n",
    "# the variational p is a random LGMM with same dimensions, and we will not learn the covariances for now\n",
    "q = LinearGaussianHMM.get_random_model(2,2)\n",
    "q.prior.parametrizations.cov.original.requires_grad = False\n",
    "q.transition.parametrizations.cov.original.requires_grad = False \n",
    "q.emission.parametrizations.cov.original.requires_grad = False \n",
    "\n",
    "\n",
    "elbo_nonlinear_emission = get_appropriate_elbo(q_description='linear_gaussian', \n",
    "                                            p_description='nonlinear_emission')\n",
    "\n",
    "elbo = elbo_nonlinear_emission(hmm.model, q)\n",
    "\n",
    "# print(elbo_nonlinear_emission(observation_sequences[0]))\n",
    "\n",
    "\n",
    "\n",
    "# optimize the parameters of the ELBO (but theta deactivated above)\n",
    "optimizer = torch.optim.Adam(params=elbo.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "eps = torch.inf\n",
    "# optimizing p \n",
    "while True:\n",
    "    epoch_loss = 0.0\n",
    "    for observations in observation_sequences: \n",
    "        optimizer.zero_grad()\n",
    "        loss = -elbo(observations)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += -loss\n",
    "    with torch.no_grad():\n",
    "        print(\"Loss:\", epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. a. i. The Johnson trick\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c528143767b35424e5fa616681845f3b9656c31f35cafe040129ce40f24d14f5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('backward_ica')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
