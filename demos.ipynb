{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on backward variational ICA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Uncomment and run the following cell if you're using Collab***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf *\n",
    "# !git clone https://github.com/mchagneux/backward_ica.git\n",
    "# !mv backward_ica/* ./\n",
    "# !rm -rf backward_ica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(-4.9738e-14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathis/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/nn/modules/container.py:597: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from src.eval import mse_expectation_against_true_states\n",
    "from src.kalman import Kalman, NumpyKalman\n",
    "from src.hmm import AdditiveGaussianHMM, LinearGaussianHMM\n",
    "from src.elbo import get_appropriate_elbo\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "torch.set_default_dtype(torch.float64) \n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "# torch.set_printoptions(precision=10)\n",
    "\n",
    "## sanity checks\n",
    "hmm = LinearGaussianHMM(state_dim=2, obs_dim=2)\n",
    "states, observations = hmm.sample_joint_sequence(10)\n",
    "\n",
    "for param in hmm.model.parameters():param.requires_grad = False\n",
    "likelihood_torch = Kalman(hmm.model).filter(observations)[4] #kalman with torch operators \n",
    "likelihood_numpy = NumpyKalman(hmm.model).filter(observations.numpy())[2] #kalman with numpy operators \n",
    "fully_linear_gaussian_elbo = get_appropriate_elbo('linear_gaussian','linear_emission')\n",
    "likelihood_via_elbo = fully_linear_gaussian_elbo(hmm.model, hmm.model)(observations) #elbo\n",
    "\n",
    "# both should be close to 0\n",
    "print(likelihood_numpy - likelihood_torch)\n",
    "print(likelihood_numpy - likelihood_via_elbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook is comprised of a series of experiments that attempt to recover expectations $\\mathbb{E}[h(z_{1:t})|x_{1:t}]$ via variational approximations, when the process $(z_t, x_t)_{t \\ge 1}$ is an HMM. The main metric $\\ell$ all along is the MSE against the true states when $h$ is a plain sum, ie\n",
    "\n",
    "$$\\ell = \\left(\\sum_{t=1}^T z_t^* - \\sum_{t=1}^T \\mathbb{E}_{q_T(z_t)}[z_t] \\right)^2$$\n",
    "\n",
    "where $q_T(z_t) = q(z_t|x_{1:T})$ is the marginal smoothing distribution at $t$.\n",
    "\n",
    "In all the following, we assume that the variational smoothing distribution factorizes as $q_\\phi(z_{1:t}|x_{1:t}) = q_\\phi(z_t|x_{1:t}) \\prod_{s=1}^{t-1} q_\\phi(z_s|z_{s+1},x_{1:s})$. We always assume that $$q_\\phi(z_t|x_{1:t}) \\sim \\mathcal{N}(\\mu_{1:t}, \\Sigma_{1:t})$$ and \n",
    "\n",
    "$$q_\\phi(z_s|z_{s+1},x_{1:s}) \\sim \\mathcal{N}(\\overleftarrow{\\mu}_{1:t}(z_{s+1}), \\overleftarrow{\\Sigma}_{1:t})$$\n",
    "\n",
    "In the following, we make several assumptions on both $p_\\theta$ and $q_\\phi$.\n",
    "\n",
    "\n",
    "In this case, not only should the expectations be correctly recovered, but parameters in $\\phi$ and $\\theta$ should be identifiable. We also know that in this case the best estimate of $z_{1:t}^*$ for any sequence is obtained via the Kalman smoothing recursions applied with parameters $\\theta$ on the observations $x_{1:t}$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Gaussian HMM \n",
    "\n",
    "First we assume that observation sequences $x_{1:T}$ arise from $p_\\theta(z_{1:t},x_{1:t})$ defined as\n",
    "$$z_t = A_\\theta z_{t-1} + a_\\theta + \\eta_\\theta$$ \n",
    "$$x_t = B_\\theta z_t + b_\\theta + \\epsilon_\\theta$$\n",
    "\n",
    "where $\\eta_\\theta \\sim \\mathcal{N}(0,Q_\\theta)$ and $\\epsilon_\\theta \\sim \\mathcal{N}(0,R_\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. a. Approximated by a linear Gaussian HMM\n",
    "\n",
    "We start by recovering $p_\\theta$ when $q_\\phi$ is in the family of the true p. We do this by prescribing the p for $q_\\phi$ in forward time with a similar HMM structure as $p_\\theta$ (but random initial parameters), and in this case the parameters of the filtering backward distributions exist via Kalman recursions and closed-form definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True evidence accross all sequences: tensor(295.0449)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6653.9401)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1505.4764)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(167.7234)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(175.6937)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(166.3655)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(109.5255)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(82.9423)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(76.5769)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(69.1806)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(63.1831)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(59.7300)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(56.5743)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(53.4567)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(50.3371)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(47.2641)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(44.3061)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(41.5159)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(38.8905)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(36.4306)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(34.1288)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(31.9815)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(29.9810)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(28.1204)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(26.3926)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(24.7898)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(23.3045)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(21.9286)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(20.6543)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(19.4740)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(18.3808)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(17.3681)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(16.4296)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(15.5595)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(14.7525)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(14.0035)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(13.3080)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(12.6616)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(12.0605)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(11.5010)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(10.9799)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(10.4940)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(10.0407)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(9.6174)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(9.2216)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(8.8514)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(8.5047)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(8.1797)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(7.8749)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(7.5887)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(7.3197)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(7.0667)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.8285)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.6041)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.3926)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.1930)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(6.0045)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.8264)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.6581)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.4989)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.3482)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.2054)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(5.0702)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.9420)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.8204)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.7050)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.5955)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.4914)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.3925)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.2984)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.2088)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.1234)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(4.0420)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.9641)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.8895)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.8180)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.7493)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.6831)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.6191)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.5571)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.4969)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.4382)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.3808)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.3245)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.2691)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.2146)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.1606)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.1071)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.0541)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(3.0015)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.9492)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.8972)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.8455)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.7941)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.7431)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.6926)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.6426)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.5932)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.5444)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.4965)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.4494)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.4033)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.3582)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.3142)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.2714)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.2297)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.1894)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.1502)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.1124)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.0757)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.0403)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.0061)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.9731)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.9411)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.9102)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.8803)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.8514)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.8233)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.7961)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.7697)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.7440)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.7190)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.6946)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.6708)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.6475)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.6248)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.6024)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5805)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5589)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5376)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5167)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.4959)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.4753)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.4549)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.4347)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.4145)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.3944)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.3743)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.3542)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.3341)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.3139)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.2937)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.2733)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.2529)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.2324)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.2117)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.1908)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.1699)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.1488)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.1276)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.1063)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.0849)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.0635)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.0421)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.0207)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.9993)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.9781)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.9570)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.9362)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.9157)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8955)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8756)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8562)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8373)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8190)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8011)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7839)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7672)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7512)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7357)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7209)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7066)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6929)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6798)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6673)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6552)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6436)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6325)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6219)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6116)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6018)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5923)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5832)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5745)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5660)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5579)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5500)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5424)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5350)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5279)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5210)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5144)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5079)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5016)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4955)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4896)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4838)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4783)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4728)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4675)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4624)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4574)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4525)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4477)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4431)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4386)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4342)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4299)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4257)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4216)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4176)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4137)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4099)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4062)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4026)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3990)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3956)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3922)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3890)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3858)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3826)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3796)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3766)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3738)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3709)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3682)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3655)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3629)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3604)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3579)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3555)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3532)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3509)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3487)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3466)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3445)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3425)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3405)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3386)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3368)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3350)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3333)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3316)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3300)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3284)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3269)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3255)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3241)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3227)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3214)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3202)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3190)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3178)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3167)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3156)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3146)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3136)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3127)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3118)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3110)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3102)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3094)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3087)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3080)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3073)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3067)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3062)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3056)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3051)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3047)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3042)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3038)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3035)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3031)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3028)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3025)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3023)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3021)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3019)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3017)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3015)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3014)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3013)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3013)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3012)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3012)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3012)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3012)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3012)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3013)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3013)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3014)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3015)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3016)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3018)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3019)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3021)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3023)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3025)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3027)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3029)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3031)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3033)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3036)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3038)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3041)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3043)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3046)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3049)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3052)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3055)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3058)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3061)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3064)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3067)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3070)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3073)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3076)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3080)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3083)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3086)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3089)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3093)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3096)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3099)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3102)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3105)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3109)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3112)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3115)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3118)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3121)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3124)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3128)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3131)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3134)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3137)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3139)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3142)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3145)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3148)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3151)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3153)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3156)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3159)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3161)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3164)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3167)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3169)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3172)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3174)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3176)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3179)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3181)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3184)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3186)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3189)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3192)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3194)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3197)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3200)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3203)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3207)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3210)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3214)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3218)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3223)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3227)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3232)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3238)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3243)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3250)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3256)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3263)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3270)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3278)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3286)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3294)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3302)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3311)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3320)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3330)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3339)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3349)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3359)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3369)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3379)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3390)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3401)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3412)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3424)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3437)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3450)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3464)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3479)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3495)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3513)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3531)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3551)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3573)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3596)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3622)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3650)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3680)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3713)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3748)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3787)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3829)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3874)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3923)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3976)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4033)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4094)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4160)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4231)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4307)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4387)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4473)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4564)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4660)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4761)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4866)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4975)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5087)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5202)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5317)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5432)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5545)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5654)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5756)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5848)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5928)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5992)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6038)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6063)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6064)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6041)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5992)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5919)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5822)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5703)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5567)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5417)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5257)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5091)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4925)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4761)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4602)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4452)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4311)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4182)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4064)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3959)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3866)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3784)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3715)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3657)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3609)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3572)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3544)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3526)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3518)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3518)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3527)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3546)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3573)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3609)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3654)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3709)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3774)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3849)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3934)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4031)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4139)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4260)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4394)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4542)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4705)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4883)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5076)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5286)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5512)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5753)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6010)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6279)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6557)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6841)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7123)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7395)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7645)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7862)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8030)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8134)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8161)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8099)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7942)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7691)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7355)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6949)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6494)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6014)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5532)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5068)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4636)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4246)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3901)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3603)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3348)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3135)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2958)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2814)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2698)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2607)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2537)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2487)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2453)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2435)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2431)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2440)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2463)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2497)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2544)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2603)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2675)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2761)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2861)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2975)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3107)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3256)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3424)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3615)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3829)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4071)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4345)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4653)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5003)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5399)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5850)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6363)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6948)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7614)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8371)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.9223)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.0172)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.1206)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.2289)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.3360)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.4315)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5010)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5278)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.4968)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.4004)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.2435)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.0461)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8377)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6467)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4909)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3747)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2936)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2395)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2045)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1823)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1686)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1606)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1563)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1544)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1538)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1536)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1533)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1527)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1517)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1505)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1496)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1492)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1494)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1501)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1512)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1530)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1553)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1584)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1621)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1667)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1720)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1783)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1854)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1936)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2029)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2140)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2287)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2591)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3756)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4785)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3635)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4230)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3710)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3702)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3947)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4829)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6444)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5540)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6515)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.6729)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.7731)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.9287)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.8941)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.0225)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.2223)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5740)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.6676)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.0440)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.2578)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.5629)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.8033)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.9008)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.7148)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(2.2333)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(1.5763)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.9864)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.5841)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3033)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1914)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1645)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3085)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.4208)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.3586)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1203)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.2173)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1166)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1564)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1133)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1228)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1157)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.1035)\n",
      "Average of \"L(theta, phi) - log(p_theta(x))\": tensor(0.0996)\n"
     ]
    }
   ],
   "source": [
    "hmm = LinearGaussianHMM(state_dim=2, obs_dim=2) # pick some true p p \n",
    "for param in hmm.model.parameters(): param.requires_grad = False # not learning the parameters of the true p for now \n",
    "\n",
    "\n",
    "\n",
    "# sampling 10 sequences from the hmm \n",
    "samples = [hmm.sample_joint_sequence(8) for _ in range(10)] \n",
    "state_sequences = [sample[0] for sample in samples]\n",
    "observation_sequences = [sample[1] for sample in samples] \n",
    "\n",
    "\n",
    "# the variational p is a random LGMM with same dimensions, and we will not learn the covariances for now\n",
    "q = LinearGaussianHMM.get_random_model(2,2)\n",
    "q.prior.parametrizations.cov.original.requires_grad = False\n",
    "q.transition.parametrizations.cov.original.requires_grad = False \n",
    "q.emission.parametrizations.cov.original.requires_grad = False \n",
    "\n",
    "# the elbo object with p and q as arguments\n",
    "elbo = fully_linear_gaussian_elbo(hmm.model, q)\n",
    "\n",
    "# optimize the parameters of the ELBO (but theta deactivated above)\n",
    "optimizer = torch.optim.Adam(params=elbo.parameters(), lr=1e-2)\n",
    "true_evidence_all_sequences = sum(Kalman(hmm.model).filter(observations)[-1] for observations in observation_sequences)\n",
    "\n",
    "print('True evidence accross all sequences:', true_evidence_all_sequences)\n",
    "\n",
    "eps = torch.inf\n",
    "# optimizing p \n",
    "while eps > 0.1:\n",
    "    epoch_loss = 0.0\n",
    "    for observations in observation_sequences: \n",
    "        optimizer.zero_grad()\n",
    "        loss = -elbo(observations)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += -loss\n",
    "    with torch.no_grad():\n",
    "        eps = torch.abs(true_evidence_all_sequences - epoch_loss)\n",
    "        print('Average of \"L(theta, phi) - log(p_theta(x))\":', eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE when smoothed with p: tensor(0.0165)\n",
      "MSE when smoothed with q: tensor(0.0165)\n"
     ]
    }
   ],
   "source": [
    "# checking expectations under approximate p when the additive functional is just the sum \n",
    "with torch.no_grad():\n",
    "    additive_functional = partial(torch.sum, dim=0)\n",
    "    smoothed_with_true_model = mse_expectation_against_true_states(state_sequences, observation_sequences, hmm.model, additive_functional)\n",
    "    smoothed_with_approximate_model = mse_expectation_against_true_states(state_sequences, observation_sequences, q, additive_functional)\n",
    "\n",
    "    print('MSE when smoothed with p:',smoothed_with_true_model)\n",
    "    print('MSE when smoothed with q:',smoothed_with_approximate_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. b. Using a neural network to compute the backward parameters instead of Kalman recursions\n",
    "We make the same assumptions on $p_\\theta$ but now we attempt to recover the backward parameters via neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A nonlinear emission p\n",
    "\n",
    "We now assume that $p_\\theta$ has a nonlinear emission distribution, ie. $x_t  = f_\\theta(z_t) + \\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. a. Approximated by a linear Gaussian p.\n",
    "We keep a linear gaussian distribution for $q_\\phi$, but we add a mapping to compute the expectation of the emission term from $p_\\theta$. We need to approximate the following quantity:\n",
    "\n",
    "$$\\mathbb{E}_{q(z_t|z_{t+1}, x_{1:t})}\\left[(x_t - f_\\theta(z_t))^T R^{{\\theta}^{-1}}(x_t - f_\\theta(z_t))\\right]$$\n",
    "\n",
    "And similarly for the last expectation under the filtering distribution: \n",
    "\n",
    "$$\\mathbb{E}_{q(z_T|x_{1:T})}\\left[(x_T - f_\\theta(z_T))^T R^{{\\theta}^{-1}}(x_T - f_\\theta(z_T))\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. a. i. A sampling-free approach. \n",
    "\n",
    "\n",
    "If we know the expectation $\\mu$ and variance $\\Sigma$ of a random variable $v$ (which need not be Gaussian):\n",
    "\n",
    "$$\\mathbb{E}_{v}\\left[(x - v)^T \\Omega (x - v)\\right] = tr(\\Sigma \\Omega) + (\\mu - x)^T \\Omega (\\mu - x)$$\n",
    "\n",
    "Suppose we a have neural network which approximates the mean and variance of $v \\sim f_\\theta(z)$ when $z \\sim p_z$, given parameters of $p_z$. Denote $\\tilde{\\mu}$ and $\\tilde{\\Sigma}$ these means and variances estimated by this network. For the filtering case, we feed the network with filtering mean and covariance at $T$ to obtain an estimate of $\\tilde{\\mu}$ and $\\tilde{\\Sigma}$, then:\n",
    "\n",
    "$$\\mathbb{E}_{q(z_T|x_{1:T})}\\left[(x_T - f_\\theta(z_T))^T R^{{\\theta}^{-1}}(x_T - f_\\theta(z_T))\\right] = tr(\\tilde{\\Sigma} \\Omega) + (\\tilde{\\mu} - x)^T R^{{\\theta}^{-1}} (\\tilde{\\mu} - x)$$\n",
    "\n",
    "For the backwards case this is not as simple, because: $\\overleftarrow{\\mu}_{1:t}$ is a function of $z_{t+1}$, therefore $\\mathbb{E}_{q(z_t|z_{t+1}, x_{1:t})}[f_\\theta(z_t)]$ and $\\mathbb{V}_{q(z_t|z_{t+1}, x_{1:t})}[f_\\theta(z_t)]$ are also functions of $z_{t+1}$. \n",
    "\n",
    "We still attempt to use one network for both the fitlering and the backwards via the following scheme: \n",
    "\n",
    "- Build a neural network $g_\\alpha(A, a, \\Sigma)$ which outputs $\\tilde{A}, \\tilde{a}$ and $\\tilde{\\Sigma}$\n",
    "- For the backwards case, use $A = \\overleftarrow{A}_{1:t}, a = \\overleftarrow{a}_{1:t}$ and $\\Sigma = \\overleftarrow{\\Sigma}_{1:t}$, and consider that $\\tilde{\\mu} = \\tilde{A}z_{t+1} + \\tilde{a}$, while $\\tilde{\\Sigma}$ does not depend on $z_{t+1}$ (which is knowingly false). In this case, the quadratic form build for $\\tilde{A}$ and $\\tilde{a}$ is a quadratic form in $z_{t+1}$ as wanted.\n",
    "- For the backwards case, use $A = 0, a = a_{1:t}$ and $\\Sigma = \\Sigma_{1:t}$, and consider that $\\tilde{\\mu} = \\tilde{a}$ (without using the output $\\tilde{A}$).\n",
    "\n",
    "*This method, which is tried below: fails to learn anything as of now.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathis/repos/backward_ica/src/elbo.py:45: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  self.cov_tilde_approximator = nn.Sequential(nn.Linear(in_features=input_shape, out_features=(obs_dim * (obs_dim + 1)) // 2, bias=True), nn.ReLU())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(1.6632e+19, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(3.0330e+14, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(1.5252e+12, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(3.8693e+12, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(5.5028e+11, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(2.6158e+10, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(4.6995e+13, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(59278587.2570, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(44851757.5932, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(6.4970e+11, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(2.2625e+08, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(10016943.9741, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(51113.1479, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(52316.1698, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(53810.7873, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(2332986.8214, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(57959.4642, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(8.9400e+11, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(7.9302e+11, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(2.3042e+08, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(80772.4505, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(95999.5821, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(21624855.9176, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(8856280.3753, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(4.9882e+08, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(1772032.5033, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(3.6369e+15, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(4.4516e+11, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(1.7604e+09, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(1.2446e+13, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(53794969.1201, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(6.2624e+17, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(8483244.7350, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(1.3607e+14, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(15071419.7332, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(19193913.5193, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(1.8019e+18, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(6.1826e+15, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(36121382.2957, grad_fn=<AddBackward0>)\n",
      "Loss: tensor(84686778.3477, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mathis/repos/backward_ica/demos.ipynb Cell 15'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mathis/repos/backward_ica/demos.ipynb#ch0000014?line=32'>33</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mathis/repos/backward_ica/demos.ipynb#ch0000014?line=33'>34</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39melbo(observations)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/mathis/repos/backward_ica/demos.ipynb#ch0000014?line=34'>35</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mathis/repos/backward_ica/demos.ipynb#ch0000014?line=35'>36</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mathis/repos/backward_ica/demos.ipynb#ch0000014?line=36'>37</a>\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39mloss\n",
      "File \u001b[0;32m~/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/backward_ica/lib/python3.9/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hmm = AdditiveGaussianHMM(state_dim=2, obs_dim=2) # we now take an hmm wih \n",
    "\n",
    "# sampling 10 sequences from the hmm \n",
    "samples = [hmm.sample_joint_sequence(8) for _ in range(10)] \n",
    "state_sequences = [sample[0] for sample in samples]\n",
    "observation_sequences = [sample[1] for sample in samples] \n",
    "\n",
    "\n",
    "# the variational p is a random LGMM with same dimensions, and we will not learn the covariances for now\n",
    "q = LinearGaussianHMM.get_random_model(2,2)\n",
    "q.prior.parametrizations.cov.original.requires_grad = False\n",
    "q.transition.parametrizations.cov.original.requires_grad = False \n",
    "q.emission.parametrizations.cov.original.requires_grad = False \n",
    "\n",
    "\n",
    "elbo_nonlinear_emission = get_appropriate_elbo(q_description='linear_gaussian', p_description='nonlinear_emission')\n",
    "\n",
    "elbo = elbo_nonlinear_emission(hmm.model, q)\n",
    "\n",
    "# print(elbo_nonlinear_emission(observation_sequences[0]))\n",
    "\n",
    "\n",
    "\n",
    "# optimize the parameters of the ELBO (but theta deactivated above)\n",
    "optimizer = torch.optim.Adam(params=elbo.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "eps = torch.inf\n",
    "# optimizing p \n",
    "while True:\n",
    "    epoch_loss = 0.0\n",
    "    for observations in observation_sequences: \n",
    "        optimizer.zero_grad()\n",
    "        loss = -elbo(observations)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += -loss\n",
    "    with torch.no_grad():\n",
    "        print(\"Loss:\", epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. a. i. Sampling and the Johnson trick.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c528143767b35424e5fa616681845f3b9656c31f35cafe040129ce40f24d14f5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('backward_ica')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
