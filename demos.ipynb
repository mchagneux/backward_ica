{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on backward variational ICA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Uncomment and run the following cell if you're using Collab***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf *\n",
    "# !git clone https://github.com/mchagneux/backward_ica.git\n",
    "# !mv backward_ica/* ./\n",
    "# !rm -rf backward_ica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from src.elbo import linear_gaussian_elbo\n",
    "from src.hmm import LinearGaussianHMM\n",
    "from src import kalman\n",
    "from jax.random import PRNGKey\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import optax\n",
    "from jax import random\n",
    "from src.misc import *\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "# jax.config.update(\"jax_debug_nans\", True)\n",
    "key = PRNGKey(0)\n",
    "import matplotlib.pyplot as plt\n",
    "# jax.config.update(\"jax_debug_nans\",'True')\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook is comprised of a series of experiments that attempt to recover expectations $\\mathbb{E}[h(z_{1:t})|x_{1:t}]$ via variational approximations, when the process $(z_t, x_t)_{t \\ge 1}$ is an HMM. The main metric $\\ell$ all along is the MSE against the true states when $h$ is a plain sum, ie\n",
    "\n",
    "$$\\ell = \\left(\\sum_{t=1}^T z_t^* - \\sum_{t=1}^T \\mathbb{E}_{q_T(z_t)}[z_t] \\right)^2$$\n",
    "\n",
    "where $q_T(z_t) = q(z_t|x_{1:T})$ is the marginal smoothing distribution at $t$.\n",
    "\n",
    "In all the following, we assume that the variational smoothing distribution factorizes as $q_\\phi(z_{1:t}|x_{1:t}) = q_\\phi(z_t|x_{1:t}) \\prod_{s=1}^{t-1} q_\\phi(z_s|z_{s+1},x_{1:s})$. We always assume that $$q_\\phi(z_t|x_{1:t}) \\sim \\mathcal{N}(\\mu_{1:t}, \\Sigma_{1:t})$$ and \n",
    "\n",
    "$$q_\\phi(z_s|z_{s+1},x_{1:s}) \\sim \\mathcal{N}(\\overleftarrow{\\mu}_{1:t}(z_{s+1}), \\overleftarrow{\\Sigma}_{1:t})$$\n",
    "\n",
    "In the following, we make several assumptions on both $p_\\theta$ and $q_\\phi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Gaussian HMM \n",
    "\n",
    "First we assume that observation sequences $x_{1:T}$ arise from $p_\\theta(z_{1:t},x_{1:t})$ defined as\n",
    "$$z_t = A_\\theta z_{t-1} + a_\\theta + \\eta_\\theta$$ \n",
    "$$x_t = B_\\theta z_t + b_\\theta + \\epsilon_\\theta$$\n",
    "\n",
    "where $\\eta_\\theta \\sim \\mathcal{N}(0,Q_\\theta)$ and $\\epsilon_\\theta \\sim \\mathcal{N}(0,R_\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. a. Approximated by a linear Gaussian HMM\n",
    "\n",
    "We start by recovering $p_\\theta$ when $q_\\phi$ is in the family of the true $p_\\theta$. We can do this by prescribing the model for $q_\\phi$ in forward time with a similar HMM structure as $p_\\theta$ (but random initial parameters), and in this case exceptionally, the parameters of the backward and filtering distributions are linked in closed-formed to the forward model via the Kalman filtering and smoothing recursions.\n",
    "\n",
    "For this experiment, not only should the expectations be correctly recovered, but parameters in $\\phi$ and $\\theta$ may be identifiable in some cases (depending on the conditioning of $p_\\theta$). We also know that in this case the best estimate of $z_{1:t}^*$ for any sequence is obtained via the Kalman smoothing recursions applied with the true parameters $\\theta$ on the observations $x_{1:t}$, so we have an optimal estimator to compare to. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking that $\\mathcal{L}(\\theta, \\theta) = \\log p_\\theta$ \n",
    "*Remark: here $\\log p$ is computed with Kalman*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Number of observations per sequence: 16"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Number of sequences: 30"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Average $\\log p_\\theta(x)$ across sequences $x$: 142.91"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Average $|\\mathcal{L}(\\theta,\\theta)- \\log p_\\theta(x)|$ across sequences: 0.00"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_dim, obs_dim = 2, 3\n",
    "num_sequences = 30\n",
    "length = 16\n",
    "display(Markdown(f'Number of observations per sequence: {length}'))\n",
    "display(Markdown(f'Number of sequences: {num_sequences}'))\n",
    "\n",
    "key, *subkeys = random.split(key,3)\n",
    "\n",
    "p_raw = LinearGaussianHMM.get_random_model(key=subkeys[0], state_dim=state_dim, obs_dim=obs_dim)\n",
    "\n",
    "p = actual_model_from_raw_parameters(p_raw)\n",
    "\n",
    "linear_gaussian_sampler = jax.vmap(LinearGaussianHMM.sample_joint_sequence, in_axes=(0, None, None))\n",
    "key, *subkeys = random.split(key, num_sequences+1)\n",
    "state_sequences, obs_sequences = linear_gaussian_sampler(jnp.array(subkeys), p, length)\n",
    "\n",
    "\n",
    "filter_obs_sequences = jax.vmap(kalman.filter, in_axes=(0, None))\n",
    "elbo_sequences = jax.jit(jax.vmap(linear_gaussian_elbo, in_axes=(None, None, 0)))\n",
    "\n",
    "average_evidence_across_sequences = jnp.mean(filter_obs_sequences(obs_sequences, p)[-1])\n",
    "display(Latex(f'Average $\\log p_\\\\theta(x)$ across sequences $x$: {average_evidence_across_sequences:.2f}'))\n",
    "average_elbo_across_sequences_with_true_model = jnp.mean(elbo_sequences(p_raw, p_raw, obs_sequences))\n",
    "display(Latex('Average $|\\mathcal{L}(\\\\theta,\\\\theta)- \\log p_\\\\theta(x)|$ across sequences: ' + f'{jnp.abs(average_evidence_across_sequences-average_elbo_across_sequences_with_true_model):.2f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing $\\phi$ when $\\theta$ is fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Average $|\\mathcal{L}(\\theta,\\phi)- \\log p_\\theta(x)|$ across sequences:77710.14"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def step(p_raw, q_raw, opt_state, batch):\n",
    "    loss_value, grads = jax.value_and_grad(linear_gaussian_elbo, argnums=1)(p_raw, q_raw, batch)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, q_raw)\n",
    "    q_raw = optax.apply_updates(q_raw, updates)\n",
    "    return p_raw, q_raw, opt_state, -loss_value\n",
    "step = jax.jit(step)\n",
    "q_raw = LinearGaussianHMM.get_random_model(key=subkeys[1], state_dim=state_dim, obs_dim=obs_dim)\n",
    "average_elbo_across_sequences_with_init_q = jnp.mean(elbo_sequences(p_raw, q_raw, obs_sequences))\n",
    "display(Latex('Average $|\\mathcal{L}(\\\\theta,\\\\phi)- \\log p_\\\\theta(x)|$ across sequences:' +  f'{jnp.abs(average_evidence_across_sequences-average_elbo_across_sequences_with_init_q):.2f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = optax.adam(learning_rate=-1e-3)\n",
    "\n",
    "def fit(p_raw, q_raw, optimizer: optax.GradientTransformation) -> optax.Params:\n",
    "    opt_state = optimizer.init(q_raw)\n",
    "\n",
    "    eps = jnp.inf\n",
    "    old_mean_epoch_elbo = -average_elbo_across_sequences_with_init_q\n",
    "    epoch_nb = 0\n",
    "    mean_elbos = [old_mean_epoch_elbo - average_evidence_across_sequences]\n",
    "    while eps > 1e-2:\n",
    "        epoch_elbo = 0.0\n",
    "        for batch in obs_sequences: \n",
    "            p_raw, q_raw, opt_state, elbo_value = step(p_raw, q_raw, opt_state, batch)\n",
    "            epoch_elbo += elbo_value\n",
    "        mean_epoch_elbo = epoch_elbo/len(obs_sequences)\n",
    "        eps = jnp.abs(mean_epoch_elbo - old_mean_epoch_elbo)\n",
    "        epoch_nb+=1\n",
    "        mean_elbos.append(mean_epoch_elbo - average_evidence_across_sequences)\n",
    "        old_mean_epoch_elbo = mean_epoch_elbo\n",
    "    return q_raw, mean_elbos\n",
    "\n",
    "\n",
    "fitted_q_raw, mean_elbos = fit(p_raw, q_raw, optimizer)\n",
    "\n",
    "plt.plot(mean_elbos)\n",
    "plt.xlabel('Epoch nb'), \n",
    "plt.ylabel('$|\\mathcal{L}(\\\\theta,\\\\phi)- \\log p_\\\\theta(x)|$')\n",
    "fitted_q = actual_model_from_raw_parameters(fitted_q_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing expectations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(E_q(h(z)), z_true): [0.0873562  0.08952309]\n",
      "MSE(E_p(h(z)), z_true): [0.02279203 0.0420618 ]\n"
     ]
    }
   ],
   "source": [
    "def squared_error_expectation_against_true_states(states, observations, approximate_linear_gaussian_model, additive_functional):\n",
    "    smoothed_states, _ = kalman.smooth(observations, approximate_linear_gaussian_model)\n",
    "    return jnp.sqrt((additive_functional(smoothed_states) - additive_functional(states)) ** 2)\n",
    "\n",
    "additive_functional = partial(jnp.sum, axis=0)\n",
    "mse_in_expectations = jax.vmap(squared_error_expectation_against_true_states, in_axes=(0,0, None, None))\n",
    "print('MSE(E_q(h(z)), z_true):', jnp.mean(mse_in_expectations(state_sequences, obs_sequences, fitted_q, additive_functional), axis=0))\n",
    "print('MSE(E_p(h(z)), z_true):', jnp.mean(mse_in_expectations(state_sequences, obs_sequences, p, additive_functional), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing values of $\\phi$ and $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>cov</th>\n",
       "      <th>weight</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prior</th>\n",
       "      <td>[0.0276, 0.0027]</td>\n",
       "      <td>[[0.0001, 0.0], [0.0, 0.0001]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transition</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[[0.0001, 0.0], [0.0, 0.0001]]</td>\n",
       "      <td>[[0.1374, 0.0], [0.0, 0.6974]]</td>\n",
       "      <td>[0.2517, 0.6986]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emission</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[[0.0001, 0.0, 0.0], [0.0, 0.0001, 0.0], [0.0,...</td>\n",
       "      <td>[[0.9776, 0.3334], [0.5715, 0.559], [0.0706, 0...</td>\n",
       "      <td>[0.1774, 0.86, 0.3161]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean  \\\n",
       "prior       [0.0276, 0.0027]   \n",
       "transition               NaN   \n",
       "emission                 NaN   \n",
       "\n",
       "                                                          cov  \\\n",
       "prior                          [[0.0001, 0.0], [0.0, 0.0001]]   \n",
       "transition                     [[0.0001, 0.0], [0.0, 0.0001]]   \n",
       "emission    [[0.0001, 0.0, 0.0], [0.0, 0.0001, 0.0], [0.0,...   \n",
       "\n",
       "                                                       weight  \\\n",
       "prior                                                     NaN   \n",
       "transition                     [[0.1374, 0.0], [0.0, 0.6974]]   \n",
       "emission    [[0.9776, 0.3334], [0.5715, 0.559], [0.0706, 0...   \n",
       "\n",
       "                              bias  \n",
       "prior                          NaN  \n",
       "transition        [0.2517, 0.6986]  \n",
       "emission    [0.1774, 0.86, 0.3161]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>cov</th>\n",
       "      <th>weight</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prior</th>\n",
       "      <td>[0.1327, 0.7465]</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0001]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transition</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[[0.0001, 0.0], [0.0, 0.0]]</td>\n",
       "      <td>[[0.0121, 0.0], [0.0, 0.6924]]</td>\n",
       "      <td>[0.9035, 0.7358]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emission</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[[0.0011, 0.0, 0.0], [0.0, 0.0004, 0.0], [0.0,...</td>\n",
       "      <td>[[0.2992, 0.9096], [0.1026, 0.9206], [0.6567, ...</td>\n",
       "      <td>[0.7979, 0.9539, 0.7919]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean  \\\n",
       "prior       [0.1327, 0.7465]   \n",
       "transition               NaN   \n",
       "emission                 NaN   \n",
       "\n",
       "                                                          cov  \\\n",
       "prior                             [[0.0, 0.0], [0.0, 0.0001]]   \n",
       "transition                        [[0.0001, 0.0], [0.0, 0.0]]   \n",
       "emission    [[0.0011, 0.0, 0.0], [0.0, 0.0004, 0.0], [0.0,...   \n",
       "\n",
       "                                                       weight  \\\n",
       "prior                                                     NaN   \n",
       "transition                     [[0.0121, 0.0], [0.0, 0.6924]]   \n",
       "emission    [[0.2992, 0.9096], [0.1026, 0.9206], [0.6567, ...   \n",
       "\n",
       "                                bias  \n",
       "prior                            NaN  \n",
       "transition          [0.9035, 0.7358]  \n",
       "emission    [0.7979, 0.9539, 0.7919]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision = 4\n",
    "def convert_to_plain_python_dict(model):\n",
    "    prior = {k: np.around(np.array(v),precision) for k,v in model.prior._asdict().items()}\n",
    "    transition = {k: np.around(np.array(v),precision) for k,v in model.transition._asdict().items()}\n",
    "    emission = {k: np.around(np.array(v),precision) for k,v in model.emission._asdict().items()}\n",
    "    return {'prior':prior, 'transition':transition, 'emission':emission}\n",
    "    \n",
    "\n",
    "print('theta')\n",
    "display(pd.DataFrame(convert_to_plain_python_dict(p)).T)\n",
    "print('phi')\n",
    "display(pd.DataFrame(convert_to_plain_python_dict(fitted_q)).T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It seems that expectations are recovered quite well even though some parameters differ.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. b. Using a neural network to compute the backward parameters instead of Kalman recursions\n",
    "We make the same assumptions on $p_\\theta$ but now we attempt to recover the backward parameters via neural network.\n",
    "\n",
    "*TODO*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A nonlinear emission p\n",
    "\n",
    "We now assume that $p_\\theta$ has a nonlinear emission distribution, ie. $x_t  = f_\\theta(z_t) + \\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. a. Approximated by a linear Gaussian p.\n",
    "We keep a linear gaussian distribution for $q_\\phi$, but we add a mapping to compute the expectation of the emission term from $p_\\theta$. We need to approximate the following quantity:\n",
    "\n",
    "$$\\mathbb{E}_{q(z_t|z_{t+1}, x_{1:t})}\\left[(x_t - f_\\theta(z_t))^T R^{{\\theta}^{-1}}(x_t - f_\\theta(z_t))\\right]$$\n",
    "\n",
    "And similarly for the last expectation under the filtering distribution: \n",
    "\n",
    "$$\\mathbb{E}_{q(z_T|x_{1:T})}\\left[(x_T - f_\\theta(z_T))^T R^{{\\theta}^{-1}}(x_T - f_\\theta(z_T))\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. a. i. A sampling-free approach. \n",
    "\n",
    "\n",
    "If we know the expectation $\\mu$ and variance $\\Sigma$ of a random variable $v$ (which need not be Gaussian):\n",
    "\n",
    "$$\\mathbb{E}_{v}\\left[(x - v)^T \\Omega (x - v)\\right] = tr(\\Sigma \\Omega) + (\\mu - x)^T \\Omega (\\mu - x)$$\n",
    "\n",
    "Suppose we a have neural network which approximates the mean and variance of $v \\sim f_\\theta(z)$ when $z \\sim p_z$, given parameters of $p_z$. Denote $\\tilde{\\mu}$ and $\\tilde{\\Sigma}$ these means and variances estimated by this network. For the filtering case, we feed the network with filtering mean and covariance at $T$ to obtain an estimate of $\\tilde{\\mu}$ and $\\tilde{\\Sigma}$, then:\n",
    "\n",
    "$$\\mathbb{E}_{q(z_T|x_{1:T})}\\left[(x_T - f_\\theta(z_T))^T R^{{\\theta}^{-1}}(x_T - f_\\theta(z_T))\\right] = tr(\\tilde{\\Sigma} \\Omega) + (\\tilde{\\mu} - x)^T R^{{\\theta}^{-1}} (\\tilde{\\mu} - x)$$\n",
    "\n",
    "For the backwards case this is not as simple, because: $\\overleftarrow{\\mu}_{1:t}$ is a function of $z_{t+1}$, therefore $\\mathbb{E}_{q(z_t|z_{t+1}, x_{1:t})}[f_\\theta(z_t)]$ and $\\mathbb{V}_{q(z_t|z_{t+1}, x_{1:t})}[f_\\theta(z_t)]$ are also functions of $z_{t+1}$. \n",
    "\n",
    "We still attempt to use one network for both the fitlering and the backwards via the following scheme: \n",
    "\n",
    "- Build a neural network $g_\\alpha(A, a, \\Sigma)$ which outputs $\\tilde{A}, \\tilde{a}$ and $\\tilde{\\Sigma}$\n",
    "- For the backwards case, use $A = \\overleftarrow{A}_{1:t}, a = \\overleftarrow{a}_{1:t}$ and $\\Sigma = \\overleftarrow{\\Sigma}_{1:t}$, and consider that $\\tilde{\\mu} = \\tilde{A}z_{t+1} + \\tilde{a}$, while $\\tilde{\\Sigma}$ does not depend on $z_{t+1}$ (which is knowingly false). In this case, the quadratic form build for $\\tilde{A}$ and $\\tilde{a}$ is a quadratic form in $z_{t+1}$ as wanted.\n",
    "- For the backwards case, use $A = 0, a = a_{1:t}$ and $\\Sigma = \\Sigma_{1:t}$, and consider that $\\tilde{\\mu} = \\tilde{a}$ (without using the output $\\tilde{A}$).\n",
    "\n",
    "*This method, which is tried below: fails to learn anything as of now.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### not reimplemented in JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. a. i. The Johnson trick\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c528143767b35424e5fa616681845f3b9656c31f35cafe040129ce40f24d14f5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('backward_ica')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
