## General modifications


We thank all reviewers for their thoughtful comments to improve the manuscript.  All of you highlighted the relevance of our theoretical contribution: this is indeed the central part of our work, and we appreciate the strong emphasis put by qKMH on that aspect and the fact that the theoretical bound is valid for a very generic variational family. 

A common criticism focuses on our empirical work which lacks (i) higher dimensional latent spaces and (ii) more complex/realistic data. In this paper, our primary empirical focus was to illustrate the theoretical bound in a controlled setting, requiring (a) a fixed and known $\theta$ with (b) an interpretable nonlinear emission function $g^\theta$ (namely, control of the injectivity) and (c) low dimensionality which allows to consider particle smoothers as oracles providing ground truth. These same conditions are also ideal to demonstrate in what ways the backward factorization leads to more expressive families while staying amongst the fast solutions which do not require Monte Carlo sampling for inference. The presentation of Section 5.2 has been revised accordingly to clarify these points. Despite these motivations, we agree that additional experimental results would greatly improve the paper. We propose the following modifications to remove the doubts made on the scalability in more complex scenarios.
- We provide a first revision of Section 5.1 and 5.2 with results now derived for 5 and 10-dimensional latent spaces, respectively. We chose such a setting to consider a more challenging experiment similar to the case considered in Campbell et al. (2021), section 5.1, as suggested by Reviewer nKds (item 4) and Reviewer  qKMH. These new experiments still support our theoretical claim and the improvements over Johnson et al. (2016) and Hälvä et al. (2021) without increasing computational requirements. 
- Upon acceptance of the paper, we also propose to add the Chaotic Recurrent Neural Network experiment from the paper of Campbell et al. to illustrate our theoretical claim and the relevance of the backward factorization with non-toy data presenting complex dynamics. We will also add an extensive study of the computational times of our method against the one we empirically compare to, and analyse the impact of dimensionality on predictive results and computational costs.


## qKMH

We sincerely thank Reviewer qKMH  for highlighting the value of our theoretical work and the relevance of the associated experiments. Please refer to the common answer regarding your concerns on more complex experimental setups. We hope that this meets your expectations.

## nKds


Thank you for this detailed review. Below is an answer to each individual point using your numbering.
- We chose the more mathematical presentation to clearly recall the links with the Bayesian filtering recursions. Per se, we do not introduce any novel type of network. Rather, one aspect of our empirical work is to highlight that the backward formulation allows to drop strong assumptions on the conjugation of the hidden dynamics with the observations, without losing analytical marginalisation of the smoothing distribution. We find that this increases the expressiveness of fast recent state-of-the-art methods like Halva et al. (2021). As such, this is intermediary between the latter work and that of Campbell et al. (2021) where marginalisation must be approximated via Monte Carlo sampling. To the best of our knowledge, this is the only solution that combines both (i) neural conjugation of hidden dynamics with observations (instead of Gaussian conjugation) and (ii) analytical computation of the backward parameters. This has been clarified in Section 5.2 (and Appendix D.3). We will add a diagram in Appendix to further detail what is modeled by the amortized network in our inference pipeline, emphasizing on how this differs from other methods. 
- The computational burden of our method is close to that of Halva et al. as it requires the same number of network evaluations (both for training and for inference). In their method, the Kalman-type filtering equations necessary to update the distribution $q_k^{\lambda}$ involve a forward pass in their inference network and a conjugation of Gaussian parameters. In our method, only one forward pass in the network is necessary, but the network is slightly larger due to the additional input of the hidden variable from time $t-1$. In addition to evaluating the forward transition kernel and the emission kernel of the true model (which is necessary for any method), eq. 7 also involves updating the parameters of backward kernel. In our experiments, this update is analytical, as for updating the backward variables involved Halva et al. Experimentally, computational times at inference are indeed of the same order of magnitude for both methods, albeit slightly worse for Halva et al. On 10-dimensional latent spaces with sequences of length 100, respectively for inference, ELBO evaluation and ELBO gradient evaluation, we report 4ms / 5.8ms / 33ms for their method, and 2.5ms / 4.4ms / 16ms for ours (on average, per sequence). We believe this comes mainly from the possibly less optimised implementation of the Gaussian conjugation that we wrote, and we will add a complete suite of benchmarks upon acceptance of the paper.
- Please refer to the common answer for concerns related to more complex experimental setup. To complement these additional experiments, we will add an analysis of the gradient variance with respect to the state-space dimension. Note that our method is indeed generic but relies solely on the pathwise estimator (with the reparametrization trick) for Monte Carlo gradient computation. As such, backpropagating through Equation 7 does not involve the score function estimator or Fisher formula, and gradient variance is not as strong as in black-box methods (e.g. https://proceedings.mlr.press/v33/ranganath14.html).
- Please refer to the common answer regarding your concerns on more complex experimental setups.    
- We will make the necessary modifications to emphasize the importance of the work of Gloaguen et al. (2022) in our results.
We understand your point of view regarding the orientation of our work. We hope that the additional experiments presented (and proposed) will make the contribution clearer. We believe that they were necessary to illustrate the theoretical results in more convincing frameworks. They also point out that the backward parametrization is sufficiently generic to be competitive with recent variational algorithms but we did not consider real data sets or very challenging deep learning use cases. 
To further clarify, rephrasing of the empirical claims has been made, in line with what was explained in the common answer. In particular, the sentence "significant improvements are made over state-of-the-art variational solutions" will be removed from the abstract for better clarity.

## DgGz



We thank this reviewer for valuing our theoretical contribution. 


Regarding points 1. and 2. and the concerns w.r.t. the empircal setting, please consult the common answer with the higher-dimensional experiments. We also propose to add a special analysis in appendix for the computational requirements of our variational method compared to Monte Carlo methods as we increase the state-space dimension. On this latter concern specifically, note that general purpose particle smoothing algorithms typically have quadratic computational complexity in the number of samples (which must be increased exponentially with the dimension for competitive performance). On the contrary, the computational complexity of training neural networks is linear in the number of parameters. Thus, increasing the expressivity of the amortized networks in variational inference frameworks is of lesser computational concern than increasing the number of Monte Carlo samples. On top of this, the performance of neural networks w.r.t dimension is less clear, and an increase in dimension may not even require an exponential increase in the number of network parameters. Finally, note that sampling-based mechanisms are typically more costly than gradient-based optimization.

In Appendix, we will provide more details on computational times required for training and inference of the various methods. 

We thank DgGz for the additional reference. 


Question: *Can you comment on the existence of the time-uniform bound right below Proposition 3.1? Is it possible to derive such a bound, e.g. in the linear/Gaussian example?*
We added details after Proposition 3.1 to clarify the time uniform bound for the control of the marginal smoothing error (which is directly obtained if all terms $c_k(\theta,\lambda)$ are upper bounded independently of $k$). This result is not surprising in the sequential Monte Carlo literature but we believed it could be of interest to highlight that it is valid for variational approximations and a natual by-product of the backward formulation.

Such a bound can be easily obtained for compactly supported latent states. It cannot be derived directly for linear and Gaussian state spaces as the existence of $\sigma_-$ is not ensured. We believe that this assumption could be weakened at the cost of significant technical works and we sticked to the very standard assumptions in the Sequential Monte Carlo literature, see for instance $\mathrm{[R1]}$, $\mathrm{[R2]}$, $\mathrm{[R3]}$. This will be further commented after assumption H2. 

- $\mathrm{[R1]}$ Dubarry, C. et al,. Bernoulli 19(5B): 2222-2249.
- $\mathrm{[R2]}$ Olsson, J. et al., Bernoulli 23(3): 1951-1996.
- $\mathrm{[R3]}$ Del Moral, P. et al., ESAIM, 44(5): 947-975.

## Tkv5


Thank you for valuing the novelty of our theoretical result. Below, we answer your concerns in the order you presented them.
- *Relevance of the backward factorization* The main goal of our work is to provide some theoretical insight for a generic class of variational smoothing family. For this, amongst all parameterizations available in the literature, the backward factorization is the most sensible choice because (i) it contains all the dependencies of the true model (ii) it can be used to build recursions that do not require a backward pass. To the best of our knowledge, it is the only factorization that shares both of these advantages, and as such it is the most appealing choice for theoretical analysis. We do stress the advantage of (ii) as a motivating element, yet in this work we voluntarily step away from the specifics of online training. Contrarily to Campbell et al. (2021) who focus specifically on the latter aspects, our main focus to better understand how backward variational methods behave when the distributions $q_k^\lambda$ are not individually constrained during training. Gradients are not computed recursively, but the tying in time of the parameters is *still* present in the batch setting, as all parameters must be jointly optimised: one goal is to understand whether H1 can be satisfied numerically without additional regularization (on this, see additional elements answered to your other questions below). Finally - as noted in Campbell et al. (2021) who briefly measure this aspect - recursive gradient computations introduce additional approximations whose impact may depend on a number of implementation choices: in their setup, online learning is either not amortized or requires to detach intermediate statistics $h_t$ at each timestep for numerical reasons. Adding the impact of these approximations in the quality of the bounds is a valuable perspective for further study but is currently not taken into account in our theoretical results. As such, introducing it in the empirical section might be confusing. If this is preferred, we may nonetheless rephrase some claims associated to these aspects, and move equation \ref{ref:eq:v_t} to Section 2 to make it clear that the recursion is common knowledge from the SSM community.
- *Additional reference* Thank you for this reference which we are aware of. At the time of writing this paper, it confirmed the relevance of the backward factorization for variational methods but had still not been properly peer-reviewed. We will add it in the text if this complies with NeurIPS rules. Note that here the intermediate (Gaussian) modeling of the distribution of the latent $x_t$ given $y_t$, unconditionally on the previous state $x_{t-1}$, is analogous to what we empirically compared our solution to. 
- Please refer to the common answer regarding your concerns on more complex experimental setups. Concerning explicit enumeration of the terms of the bounds in the linear and Gaussian case, we can add graphs for the values of $c_k(\theta, \lambda)$ over time if this is considered a valuable addition upon acceptance of the paper.
- *On H1* As commonly done in the context of SMC, we control the global smoothing error by decomposing it in $n$ local error terms. As depicted in the proof, this assumption came as a natural way to control local error terms (see the proof of Proposition 3.1, appendix A). This assumption provides a theoretical (but maybe not practical) way to quantify the quality of the variational backward kernel with respect to a true forward model. To compare two backward kernels, one would need to find each corresponding optimal sequence of $\bar{q}_k$ and then compare the  corresponding sequence of constants $c_k$. It is certainly of great interest for future research to investigate whether the optimal sequence of $\bar{q}_k$ can be derived or, to find a way to bypass this assumption when trying to control the smoothing errors.
- *Exploding bound* This relevant remark would certainly need further research to be fully answered. As it is noticed, the proposed bound might be too coarse in the context of models with nearly deterministic hidden dynamics. However, even in this context we still guarantee that the error will increase at most linearly with $n$. Refining this bound is certainly of great interest (in this context as in the classical context of SMC where the same hypothesis H2 is common).  We believe that this would imply significant technical works outside of the scope of this paper. 


Question: *It is not clear to me what the learning signal is for the marginals for $q_k^\lambda$ for $k < n$. This is because when you are learning with the batch ELBO $1:n$, only the marginal at time $n$ and the set of reverse kernels appear in the loss. The marginals produced by the RNN for times $k < n$ only appear implicitly in the form for $q_{k-1|k}^\lambda$ along with the learned  dynamics $m_k$. Can we be sure then $q_k^\lambda$ gives a reasonable estimate for the marginal at time $k$?* 

Indeed, in the batch setting, the ELBO computed using recursion 7 forms a telescoping series where only the terms $q_n^\lambda$ and $\tilde{q}_1^\lambda$ remain, but parameters of the backward kernels are directly derived from the parameters of the intermediate distributions $\tilde{q}_k^\lambda$, $k < n$. The learning signal for the latter is only such that the joint smoothing error is minimized. As stressed in the text, we do not assume that the intermediate sequence of $\tilde{q}_k^\lambda$ for $k < n$ is an approximation of the true filtering distributions. In the theoretical partnotation with $q_n^\lambda$ in the theoretical part). Experimentally, we observe however that this is the case when comparing them side-by-side with particle filters, even without additional learning signals. This suggests that there is a unique solution to minimize the bound in H1 and a perspective of this work is to refine this result with finer theoretical understanding. The experimental comparisons may be added in Appendix. 